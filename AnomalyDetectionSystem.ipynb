{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MSc Individual Project: Anomaly Detection for Assisted Independent Living\n",
    "\n",
    "Author: Christina Spanellis\n",
    " \n",
    "Sections 1-4 of this notebook define the necessary method definitions and constants for this project.\n",
    "\n",
    "Section 5 contains code to build and test the system\n",
    "\n",
    "## Sections\n",
    "### 1. [Data preparation and pre-processing](#section1)\n",
    "### 2. [Anomalous Data Generation Module](#section2)\n",
    "### 3. [Prediction Module](#section3)\n",
    "### 4. [Anomaly Detection Module](#section4)\n",
    "### 5. [Running the system](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages for the project\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from keras import models\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.graphics.tsaplots import plot_acf\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import seaborn as sns\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "# from keras.metrics import mean_squared_error\n",
    "from numpy import sqrt\n",
    "import os.path"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Section 1: Data preparation and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different data sets had to be cleaned and prepared to be in a suitable format for the prediction module. \n",
    "\n",
    "Data set 1: CASAS HH101\n",
    "\n",
    "Data set 2: CASAS HH102\n",
    "\n",
    "The below definitions define the constants and logic needed for loading and pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS AND GLOBALS DEFINITION\n",
    "\n",
    "SENSOR_EVENT_WINDOW_SIZE = 19\n",
    "HH101_PREDICTION_SENSORS = [\"M003\", \"LS002\", \"M004\", \"M005\", \"LS005\", \"MA015\", \"M012\", \"M010\"]\n",
    "HH102_PREDICTION_SENSORS = [\"M007\", \"T105\", \"LS008\", \"M004\", \"M002\", \"LS010\", \"MA009\", \"M018\", \"LS002\"]\n",
    "NUMBER_IN_FEATURES = None\n",
    "DATASET = None\n",
    "NUMBER_PREDICTIONS = None\n",
    "ENABLE_PLOTS = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the hh101 data set\n",
    "def load_hh101():\n",
    "    # load the data set\n",
    "    hh101 = read_csv('datasets/hh101/hh101.csv', names=[\"Sensor\",1,2,\"Value\",\"Type\"])\n",
    "    hh101.drop(columns={1,2,\"Type\"}, inplace=True)\n",
    "    # replace string values and drop unwanted sensor readings\n",
    "    hh101 = hh101[hh101[\"Sensor\"].str.contains(\"BAT\") == False]\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"ON\" : 1.0, \"OFF\" : 0.0})\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"ABSENT\" : 1.0, \"PRESENT\" : 0.0})\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"OPEN\" : 1.0, \"CLOSE\" : 0.0})\n",
    "    # creating a mapping of the sensor names to keep track of them\n",
    "    count = 0\n",
    "    hh101_sensor_id_mapping = {}\n",
    "    for sensor in hh101[\"Sensor\"].values:\n",
    "        if sensor not in hh101_sensor_id_mapping:\n",
    "            hh101_sensor_id_mapping[sensor] = count\n",
    "            count+=1\n",
    "    hh101_reversed_mapping = {y: x for x, y in hh101_sensor_id_mapping.items()}\n",
    "    return (hh101, hh101_sensor_id_mapping, hh101_reversed_mapping)\n",
    "\n",
    "# load the hh102 dataset \n",
    "def load_hh102():\n",
    "    # load the data set\n",
    "    hh102 = read_csv('datasets/hh102/hh102.csv', names=[\"Sensor\",1,2,\"Value\",\"Type\"])\n",
    "    hh102.drop(columns={1,2,\"Type\"}, inplace=True)\n",
    "    # replace string values and drop unwanted sensor readings\n",
    "    hh102 = hh102[hh102[\"Sensor\"].str.contains(\"BAT\") == False]\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"ON\" : 1.0, \"OFF\" : 0.0})\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"ABSENT\" : 1.0, \"PRESENT\" : 0.0})\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"OPEN\" : 1.0, \"CLOSE\" : 0.0})\n",
    "    # creating a mapping of the sensor names to keep track of them\n",
    "    count = 0\n",
    "    hh102_sensor_id_mapping = {}\n",
    "    for sensor in hh102[\"Sensor\"].values:\n",
    "        if sensor not in hh102_sensor_id_mapping:\n",
    "            hh102_sensor_id_mapping[sensor] = count\n",
    "            count+=1\n",
    "    hh102_reversed_mapping = {y: x for x, y in hh102_sensor_id_mapping.items()}\n",
    "    return (hh102, hh102_sensor_id_mapping, hh102_reversed_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_sensors(dataset, sensors, mapping):\n",
    "    for i in range (len(sensors)):\n",
    "        sensors[i] = mapping[sensors[i]]\n",
    "    return dataset.drop(columns=sensors)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_decomp(dataset, reversed_mapping):\n",
    "    dataset = dataset.copy()\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    dataset[dataset.columns] = min_max_scaler.fit_transform(dataset)\n",
    "    pca = PCA(0.9)\n",
    "    components = pca.fit_transform(dataset)\n",
    "    n_pcs = pca.components_.shape[0]\n",
    "    # get the index of the most important feature on EACH component\n",
    "    most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "    initial_feature_names = dataset.columns\n",
    "    # get the most important feature names\n",
    "    most_important_features = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "    most_important_features = [i for n, i in enumerate(most_important_features) if i not in most_important_features[:n]] \n",
    "    exp_var_pca = pca.explained_variance_ratio_\n",
    "    cum_sum_eigenvalues = np.cumsum(exp_var_pca)\n",
    "    if (ENABLE_PLOTS):\n",
    "        if (check_stationary(dataset, most_important_features)):\n",
    "            print(\"All selected features stationary\")\n",
    "        check_autocorrelation(dataset, most_important_features, reversed_mapping)\n",
    "\n",
    "    for i in range(len(most_important_features)):\n",
    "            most_important_features[i] = reversed_mapping[most_important_features[i]]\n",
    "    if (ENABLE_PLOTS):\n",
    "        pyplot.figure(figsize=(15, 5))\n",
    "        pyplot.bar(range(0,len(exp_var_pca)), exp_var_pca, alpha=0.5, align='center', label='Individual explained variance')\n",
    "        pyplot.step(range(0,len(cum_sum_eigenvalues)), cum_sum_eigenvalues, where='mid',label='Cumulative explained variance')\n",
    "        pyplot.xlabel('Principal Component')\n",
    "        pyplot.ylabel('Explained Variance')\n",
    "        pyplot.xticks(range(0,len(exp_var_pca)))\n",
    "        pyplot.title(\"Cumulative explained variance in \" + DATASET.upper())\n",
    "        pyplot.savefig(\"data_plots/\"+DATASET +\"/pca\")\n",
    "    return most_important_features\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_stationary(pca, n_components):\n",
    "    for column in n_components:\n",
    "        result = adfuller(pca[column])[1]\n",
    "        if result > 0.05:\n",
    "            return False\n",
    "    return True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_autocorrelation(dataset, most_important_features, reversed_mapping):\n",
    "    axs = None\n",
    "    if (len(most_important_features)  % 2 == 0):\n",
    "        fig, axs = pyplot.subplots(int(len(most_important_features) / 2),2,  sharex=True, sharey=True, figsize=(11,8))\n",
    "    else:\n",
    "        fig, axs = pyplot.subplots(int(len(most_important_features) / 2)+1,2,  sharex=True, sharey=True, figsize=(11,8))\n",
    "\n",
    "    axis = axs.flat\n",
    "    for i, column in enumerate(most_important_features):\n",
    "        plot_acf(dataset[column], lags=50, ax = axis[i], alpha=0.05, title=\"Sensor \" + reversed_mapping[column]  +\" autocorrelation\")\n",
    "    if (len(axis) > len(most_important_features)):\n",
    "        fig.delaxes(axis[-1])\n",
    "    \n",
    "    fig.supxlabel(\"Lags\")\n",
    "    fig.supylabel(\"ACF\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(\"data_plots/\" + DATASET + \"/autocorrelation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method transforms the data set into a format where the columns represent the various sensor values and segment the data into 20 event sensor windows.\n",
    "\n",
    "This means that each row in the data set represents the activations for the previous 20 sensor event activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, sensor_id_mapping,create=False):\n",
    "    count = 0\n",
    "    if os.path.isfile(\"datasets/\"  + DATASET +\"/selected_data.csv\"):\n",
    "        selected = pandas.read_csv(\"datasets/\"  + DATASET +\"/selected_data.csv\", index_col=\"Time\")\n",
    "        extracted = pandas.read_csv(\"datasets/\"  + DATASET +\"/extracted_data.csv\", index_col=\"Time\")\n",
    "        columns = [i for i in range (0,len(sensor_id_mapping))]\n",
    "        selected.columns = columns\n",
    "        columns = [i for i in range (0,6)]\n",
    "        extracted.columns = columns\n",
    "        return selected, extracted\n",
    "    else:\n",
    "        data = []\n",
    "        features = []\n",
    "        starting_date_time = datetime.strptime(dataset.index[0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "        starting_date_time = starting_date_time.replace(microsecond=0)\n",
    "        sensor_vals = [0.0] * len(sensor_id_mapping)\n",
    "        feature_vals = [0.0] * 6\n",
    "        sensor_counts = {}\n",
    "        prev_id = 0\n",
    "        prev_dom_sens = 0\n",
    "        event_count = 0 ## counter used to segment the data into sensor event windows\n",
    "        for i, row in dataset.iterrows():\n",
    "            curr_date_time =  datetime.strptime(i, '%Y-%m-%d %H:%M:%S.%f')\n",
    "            curr_date_time = curr_date_time.replace(microsecond=0)\n",
    "            if (event_count >= SENSOR_EVENT_WINDOW_SIZE):\n",
    "                values = [starting_date_time.strftime(\"%m-%d-%Y %H:%M:%S\")]\n",
    "                values.extend(sensor_vals)\n",
    "                data.append(values)\n",
    "                ## new\n",
    "                if (create):\n",
    "                    feature_vals[0] = (curr_date_time - starting_date_time).seconds\n",
    "                    feature_vals[1] = curr_date_time.hour\n",
    "                    feature_vals[2] = max(sensor_counts, key=sensor_counts.get)\n",
    "                    feature_vals[3] = curr_date_time.day\n",
    "                    feature_vals[4] = prev_dom_sens\n",
    "                    feature_vals[5] = prev_id\n",
    "                    prev_dom_sens = max(sensor_counts, key=sensor_counts.get)\n",
    "                    values = [starting_date_time.strftime(\"%m-%d-%Y %H:%M:%S\")]\n",
    "                    values.extend(feature_vals)\n",
    "                    features.append(values)\n",
    "                    sensor_counts = {}\n",
    "\n",
    "                ## new\n",
    "                starting_date_time = curr_date_time\n",
    "                for sensor in sensor_id_mapping:\n",
    "                    if \"D\" in sensor or \"M\" in sensor:\n",
    "                        sensor_vals[sensor_id_mapping[sensor]] = 0.0\n",
    "\n",
    "                # sensor_vals = [0.0] * len(sensor_id_mapping)\n",
    "                event_count = 0\n",
    "            event_count +=1\n",
    "            if \"D\" in row[\"Sensor\"] or \"M\" in row[\"Sensor\"]:\n",
    "                if sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] == 0.0:\n",
    "                    sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] = 1.0\n",
    "                else:\n",
    "                    sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] += 1.0\n",
    "            else:\n",
    "                sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] = row[\"Value\"]\n",
    "            if (create):\n",
    "                if sensor_id_mapping[row[\"Sensor\"]] in sensor_counts:\n",
    "                    sensor_counts[sensor_id_mapping[row[\"Sensor\"]]] +=1\n",
    "                else:\n",
    "                    sensor_counts[sensor_id_mapping[row[\"Sensor\"]]] =1\n",
    "            prev_id = sensor_id_mapping[row[\"Sensor\"]]\n",
    "            if row[\"Sensor\"] == \"D001\":\n",
    "                count+=1\n",
    "        columns = [i for i in range (0,len(sensor_id_mapping))]\n",
    "\n",
    "        final_columns = [\"Time\"]\n",
    "        final_columns.extend(columns)\n",
    "        # set the index of the dataframe to be the time column\n",
    "        new_data = pandas.DataFrame.from_records(data, columns=final_columns)\n",
    "        new_data[\"Time\"] = pandas.to_datetime(new_data[\"Time\"], format='%m-%d-%Y %H:%M:%S')\n",
    "        new_data = new_data.set_index(\"Time\")\n",
    "        new_data.to_csv(\"datasets/\"  + DATASET +\"/selected_data.csv\")\n",
    "\n",
    "        ##\n",
    "        extracted_features = None\n",
    "        if (create):\n",
    "            columns = [i for i in range (0,6)]\n",
    "\n",
    "            final_columns = [\"Time\"]\n",
    "            final_columns.extend(columns)\n",
    "            extracted_features =  pandas.DataFrame.from_records(features, columns=final_columns)\n",
    "        ##\n",
    "\n",
    "        extracted_features[\"Time\"] = pandas.to_datetime(extracted_features[\"Time\"], format='%m-%d-%Y %H:%M:%S')\n",
    "        extracted_features = extracted_features.set_index(\"Time\")\n",
    "        extracted_features.to_csv(\"datasets/\"  + DATASET +\"/extracted_data.csv\")\n",
    "        return new_data, extracted_features\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method plots all the data (non-normalised) after formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cleaned_data(data, reversed_mapping):\n",
    "    changed_legend = data.rename(columns = reversed_mapping)\n",
    "    ax = changed_legend.plot(subplots=True,figsize=(12,24), sharey=True, ylabel=\"Sensor Value\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(\"data_plots/\" + DATASET + \"/cleaned_data\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method transforms the series into a format suitable for a supervised learning problem.\n",
    "\n",
    "Eg. [Sensor1(t-1), Sensor2(t-1), Sensor1(t), Sensor2(t)]\n",
    "\n",
    "Where readings at t-1 represent the sensor activations for the period before the activations at t.\n",
    "\n",
    "Sensor activations at time t then become the ground truth values for activations at t-1 in the prediction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_series_to_supervised(new_data, prediction_sensors, important_features, reversed_mapping, create=False, extracted=None):\n",
    "    if os.path.isfile(\"datasets/\"  + DATASET +\"/final_selected_dataset.csv\"):\n",
    "        columns = [i for i in range (0,len(reversed_mapping))]\n",
    "        return (pandas.read_csv(\"datasets/\"  + DATASET +\"/final_selected_dataset.csv\", index_col=[0]), pandas.read_csv(\"datasets/\"  + DATASET +\"/normalised_dataset.csv\",  names=columns)),pandas.read_csv(\"datasets/\"  + DATASET +\"/final_extracted_dataset.csv\", index_col=[0])\n",
    "    else:\n",
    "        df = new_data.copy()\n",
    "        # scale values\n",
    "        values = df.values\n",
    "        min_max_scaler = MinMaxScaler()\n",
    "        scaled_values = min_max_scaler.fit_transform(values)\n",
    "        normalized_df = pandas.DataFrame(scaled_values)\n",
    "        normalized_df.to_csv(\"datasets/\"  + DATASET +\"/normalised_dataset.csv\")\n",
    "        if (create):\n",
    "            new_values = extracted.values\n",
    "            min_max_scaler = MinMaxScaler()\n",
    "            new_scaled_values = min_max_scaler.fit_transform(new_values)\n",
    "            new_normalized_df = pandas.DataFrame(new_scaled_values)\n",
    "        n_vars = len(normalized_df.columns)\n",
    "        time_Series = normalized_df.copy().set_index(df.index)\n",
    "        cols, names = list(), list()\n",
    "        new_cols = list()\n",
    "        # input sequence (t-n, ... t-1)\n",
    "        for i in range(1, 0, -1):\n",
    "            sequence = normalized_df.shift(i)\n",
    "            sequence = sequence.rename(columns=reversed_mapping)\n",
    "            sequence = sequence[important_features]\n",
    "            cols.append(sequence)\n",
    "            names += [('%s(t-%d)' % (label, i)) for label in sequence.columns]\n",
    "        if (create):\n",
    "             for i in range(1, 0, -1):\n",
    "                sequence = new_normalized_df.shift(i)\n",
    "                new_cols.append(sequence)\n",
    "        # forecast sequence (t, t+1, ... t+n)\n",
    "        for i in range(0, 1):\n",
    "            sequence = normalized_df.shift(-i)\n",
    "            sequence = sequence.rename(columns=reversed_mapping)\n",
    "            sequence = sequence[prediction_sensors]\n",
    "            cols.append(sequence.shift(-i))\n",
    "            names += [('%s(t)' % (label)) for label in sequence.columns]\n",
    "        if (create):\n",
    "            for i in range(0, 1):\n",
    "                sequence = normalized_df.shift(-i)\n",
    "                sequence = sequence.rename(columns=reversed_mapping)\n",
    "                sequence = sequence[prediction_sensors]\n",
    "                new_cols.append(sequence.shift(-i))\n",
    "        # put it all together\n",
    "        agg = concat(cols, axis=1)\n",
    "        agg.columns = names\n",
    "        # drop rows with NaN values\n",
    "        agg.dropna(inplace=True)\n",
    "        agg.to_csv(\"datasets/\"  + DATASET +\"/final_selected_dataset.csv\")\n",
    "\n",
    "        extracted_data = concat(new_cols, axis=1)\n",
    "        extracted_data.dropna(inplace=True)\n",
    "        extracted_data.to_csv(\"datasets/\"  + DATASET +\"/final_extracted_dataset.csv\")\n",
    "\n",
    "        return (agg, normalized_df), extracted_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method plots the activations for the sensors in the data set, grouped into figures by sensor type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalised_sensor_activations(normalized_df, reversed_mapping):\n",
    "    changed_legend = normalized_df.rename(columns = reversed_mapping)\n",
    "    doors =[]\n",
    "    lights = []\n",
    "    temp = []\n",
    "    motion = []\n",
    "    for key in reversed_mapping:\n",
    "        if \"D\" in reversed_mapping[key]:\n",
    "            doors.append(key)\n",
    "        elif \"L\" in reversed_mapping[key]:\n",
    "            lights.append(key)\n",
    "        elif \"T1\" in reversed_mapping[key]:\n",
    "            temp.append(key)\n",
    "        else:\n",
    "            motion.append(key)\n",
    "    sensors = [doors, lights, temp, motion]\n",
    "    names = [\"Door Sensors\", \"Light Sensors\", \"Temperature Sensors\", \"Motion Sensors\"]\n",
    "    for i, sensor in enumerate(sensors):\n",
    "        if \"Door\" or \"Temperature\" in names[i]:\n",
    "            figsize = (11,4)\n",
    "            if DATASET == \"HH102\":\n",
    "                figsize = (11,8)\n",
    "        if (len(sensor) % 2 == 0):\n",
    "            fig, axs = pyplot.subplots(int(len(sensor) / 2),2,  sharex=True, sharey=True, figsize=(11,8))\n",
    "        else:\n",
    "            fig, axs = pyplot.subplots(int(len(sensor) / 2)+1,2,  sharex=True, sharey=True, figsize=(11,4))\n",
    "\n",
    "        count = 0\n",
    "        for ax in axs.flat:\n",
    "            if (count < len(sensor)):\n",
    "                ax.plot(changed_legend[reversed_mapping[sensor[count]]])\n",
    "                ax.set_title(reversed_mapping[sensor[count]])\n",
    "                ax.set_xticks([0, 10000, 20000, 30000, 40000, 50000])\n",
    "                ax.set_yticks([0.0, 0.5, 1.0])\n",
    "                count += 1\n",
    "            else:\n",
    "                fig.delaxes(ax)\n",
    "        for ax in axs.flat:\n",
    "            ax.label_outer()\n",
    "        fig.suptitle(names[i])\n",
    "        fig.supxlabel(\"SEW\")\n",
    "        fig.supylabel(\"Sensor Value\")\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(\"data_plots/\" + DATASET + \"/\" +names[i],dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discover the features with the highest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_correlations(dataset, reversed_mapping):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_values = min_max_scaler.fit_transform(dataset.values)\n",
    "    normalized_df = pandas.DataFrame(scaled_values)\n",
    "    normalized_df = normalized_df.rename(columns = reversed_mapping)\n",
    "    corrmat = normalized_df.corr(method='pearson', min_periods=100)\n",
    "    corrmat = np.abs(corrmat)\n",
    "    sns.set(context=\"paper\", font=\"monospace\")\n",
    "    f, ax = pyplot.subplots(figsize=(12, 9))\n",
    "    sns.heatmap(corrmat, vmax=0.8, square=True, xticklabels = True, yticklabels = True)\n",
    "    pyplot.title(DATASET.upper() + \" Pearson correlation values between sensors (absolute valued).\")\n",
    "    pyplot.xlabel(\"Sensor ID\")\n",
    "    pyplot.ylabel(\"Sensor ID\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(\"data_plots/\" + DATASET + \"/correlations\")\n",
    "    triangluar_corrmat = np.triu(corrmat, k=1)\n",
    "    values = np.where(triangluar_corrmat >= 0.6)\n",
    "    values = list(zip(values[0], values[1]))\n",
    "    for x in range (len(values)):\n",
    "        values[x] = (reversed_mapping[values[x][0]], reversed_mapping[values[x][1]], triangluar_corrmat[values[x][0]][values[x][1]])\n",
    "    return values \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be separated out into training (70%), testing (20%) and anomalous portions (10%).\n",
    "\n",
    "The anomalous portion of the data is held back for synthetic anomaly injection to later be used to test the AD system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(dataset):\n",
    "    values = dataset.values\n",
    "    train_split = int(0.7 * len(values))\n",
    "    anomaly_split = int(0.9 * len(values))\n",
    "    train = values[:train_split, :]\n",
    "    test = values[train_split:anomaly_split, :]\n",
    "    anomalies = values[anomaly_split:, :]\n",
    "\n",
    "    train_x, train_y = train[:, :NUMBER_IN_FEATURES], train[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    test_x, test_y = test[:, :NUMBER_IN_FEATURES], test[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    anomaly_x, anomaly_y = anomalies[:, :NUMBER_IN_FEATURES], anomalies[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    train_x = np.asarray(train_x).astype(np.float32)\n",
    "    train_y = np.asarray(train_y).astype(np.float32)\n",
    "    test_y = np.asarray(test_y).astype(np.float32)\n",
    "    test_x = np.asarray(test_x).astype(np.float32)\n",
    "    train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "    test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
    "    return (train_x, train_y, test_x, test_y, anomaly_x, anomaly_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "## Section 3: Prediction Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains the logic to train models for the Prediction Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to save trained models and plot their loss (used for experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_model_and_plot(model, history, type):\n",
    "    model.save(\"best_models/\" + DATASET + \"/\" + type + \"/best_model\", history)\n",
    "    if (ENABLE_PLOTS):\n",
    "        pyplot.plot(history.history['loss'], label='Loss')\n",
    "        pyplot.plot(history.history['val_loss'], label='Validation Loss')\n",
    "        pyplot.xlabel(\"Epochs\")\n",
    "        pyplot.ylabel(\"Loss\")\n",
    "        pyplot.title(\"Training and validation loss of final \"+ DATASET.upper() +\" model.\")\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.legend()\n",
    "        pyplot.savefig(\"best_models/\"+ DATASET +\"/best_model\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a model suitable for hyper parameter tuning in in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model(hp):\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('input_lstm_layer', min_value = 50, max_value = 500, step = 50), input_shape=(train_x.shape[1], train_x.shape[2]), return_sequences = True))\n",
    "    model.add(LSTM(hp.Int('final_lstm_layer', min_value = 50, max_value = 500, step = 50)))\n",
    "    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    model.add(Dense(NUMBER_PREDICTIONS, activation = hp.Choice('dense_activation', values=['sigmoid'],default='sigmoid')))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(200, input_shape=(train_x.shape[1], train_x.shape[2])))\n",
    "    model.add(Dense(NUMBER_PREDICTIONS, activation = 'sigmoid'))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and use the keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(x_train, y_train, type):\n",
    "    tuner = kt.BayesianOptimization(\n",
    "        build_model,\n",
    "        objective='mse',\n",
    "        max_trials=20,\n",
    "        directory=\"tensorflow/\"+DATASET+\"/\" + type +\"/\",\n",
    "        project_name=\"models\",\n",
    "        overwrite = False\n",
    "    )\n",
    "    tuner.search(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size = 128,\n",
    "        validation_split=0.2,\n",
    "        epochs = 500,\n",
    "        callbacks=[callbacks.TensorBoard(log_dir=\"/tmp/tb_logs/\"+DATASET, histogram_freq=1), callbacks.EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=30), callbacks.ModelCheckpoint('best_model_es.h5',monitor='val_loss',mode='min',save_best_only=True)],\n",
    "\n",
    "    )\n",
    "    return tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_baseline(model, train_x, train_y, test_x, test_y,test=False):\n",
    "    if (test):\n",
    "        history = model.fit(train_x, train_y, epochs=10, validation_data=(test_x, test_y))\n",
    "    else:\n",
    "        history = model.fit(train_x, train_y, epochs=80, validation_data=(test_x, test_y))\n",
    "    # save_model_and_plot(model, history)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train new model with best hyper-parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_final_model(train_x, train_y, test_x, test_y, extracted=False):\n",
    "    model = None\n",
    "    history = None\n",
    "    type =\"selected\"\n",
    "    if extracted:\n",
    "        type=\"extracted\"\n",
    "    filename = \"best_models/\" + DATASET +\"/\"+ type + \"/best_model\"\n",
    "    print(type)\n",
    "    if os.path.isdir(filename):\n",
    "        model = models.load_model(filename)\n",
    "    else:\n",
    "        tuner = tune_model(train_x, train_y, type)\n",
    "        model, history = train_final_model(train_x, train_y, test_x, test_y, tuner, type)\n",
    "    return model, history\n",
    "\n",
    "def train_final_model(train_x, train_y, test_x, test_y, tuner, type):\n",
    "    print(tuner.get_best_hyperparameters()[0])\n",
    "    model = tuner.hypermodel.build(tuner.get_best_hyperparameters()[0])\n",
    "    history = model.fit(train_x, train_y, epochs=100, validation_data=(test_x, test_y))\n",
    "    save_model_and_plot(model, history, type)\n",
    "    return model, history\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import r2_score\n",
    "def predict(anomaly_x, model, anomaly_y):\n",
    "    predictions = []\n",
    "    errors = []\n",
    "    sensor_errors = []\n",
    "    r2_s = []\n",
    "    for i in range (len(anomaly_x)):\n",
    "        input = anomaly_x[i]\n",
    "        ground_truth = anomaly_y[i]\n",
    "        input = input.reshape((1, 1, input.shape[0]))\n",
    "        pred = model.predict(input, batch_size=1, verbose=0)\n",
    "        pred = pred[0]\n",
    "        predictions.append(pred)\n",
    "        sensor_errors_temp = []\n",
    "        for i in range (len(ground_truth)):\n",
    "            sensor_errors_temp.append(mean_squared_error([ground_truth[i]], [pred[i]]))\n",
    "        sensor_errors.append(sensor_errors_temp)\n",
    "        errors.append(mean_squared_error(ground_truth, pred))\n",
    "        r2_s.append(r2_score(ground_truth, pred))\n",
    "    predictions = np.array(predictions)\n",
    "    pred_sens = HH102_PREDICTION_SENSORS\n",
    "    if DATASET == \"hh101\":\n",
    "        pred_sens = HH101_PREDICTION_SENSORS\n",
    "    df = pandas.DataFrame(data = sensor_errors, columns=pred_sens)        \n",
    "    # return predictions.reshape(predictions.shape[0], predictions.shape[2]), errors\n",
    "    return errors, r2_s, predictions, df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_sensor_mse(selected, extracted):\n",
    "    data = pandas.DataFrame(columns = ['A'])\n",
    "    cols = []\n",
    "    my_pal = {}\n",
    "    pred_sens = HH101_PREDICTION_SENSORS\n",
    "    if DATASET == \"hh102\":\n",
    "        pred_sens = HH102_PREDICTION_SENSORS\n",
    "    for sensor in pred_sens:\n",
    "        data[sensor + \" 1\"]= selected[sensor]\n",
    "        data[sensor+ \" 2\"]= extracted[sensor]\n",
    "        cols.append(sensor + \" 1\")\n",
    "        my_pal[sensor+ \" 1\"] = \"g\"\n",
    "        cols.append(sensor+ \" 2\")\n",
    "        my_pal[sensor+ \" 2\"] = \"b\"\n",
    "    del data[\"A\"]\n",
    "    df = pandas.DataFrame(data, columns=cols)\n",
    "    b = sns.boxplot(data = df, showfliers=False, whis=1.5, palette=my_pal)\n",
    "    b.set_ylabel(\"MSE\", fontsize=12)\n",
    "    b.set_xlabel(\"Sensor\", fontsize=12)\n",
    "    b.set_title(\"MSE per sensor in \" + DATASET.upper() +\" models\", fontsize=14)\n",
    "    # # b.set_yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.14, 0.16])\n",
    "    sns.set(rc = {'figure.figsize':(20,12)})\n",
    "    sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "\n",
    "    f = b.get_figure()\n",
    "    f.savefig(\"data_plots/\" + DATASET+\"/sensor_mse\")\n",
    "    sns.despine(offset = 5, trim = True)\n",
    "\n",
    "def plot_final_mse(selected_hh101, extracted_hh101, selected_hh102, extracted_hh102):\n",
    "    data = pandas.DataFrame(columns = ['A'])\n",
    "    selected_hh101\n",
    "    data[\"HH101 Selected\"] = selected_hh101\n",
    "    data[\"HH101 Extracted\"] = extracted_hh101\n",
    "    data[\"HH102 Selected\"] = selected_hh102[:len(selected_hh101)]\n",
    "    data[\"HH102 Extracted\"] = extracted_hh102[:len(selected_hh101)]\n",
    "    del data[\"A\"]\n",
    "    df = pandas.DataFrame(data)\n",
    "    b = sns.boxplot(data = df, showfliers=False, whis=1.5)\n",
    "    b.set_ylabel(\"MSE\", fontsize=12)\n",
    "    b.set_xlabel(\"Model\", fontsize=12)\n",
    "    b.set_title(\"Final prediction MSE in all models\", fontsize=14)\n",
    "    # # b.set_yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.14, 0.16])\n",
    "    sns.set(rc = {'figure.figsize':(12,8)})\n",
    "    sns.set(rc={\"figure.dpi\":300, 'savefig.dpi':300})\n",
    "\n",
    "    f = b.get_figure()\n",
    "    f.savefig(\"data_plots/final_mse\")\n",
    "    sns.despine(offset = 5, trim = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Section 2: Anomamlous Data Generation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains the logic for the Anomalous Data Generation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes the test data and inserts anomalies into a specified fraction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def get_stats(dataset):\n",
    "    return (dataset.mean(axis=0), dataset.min(axis=0), dataset.max(axis=0))\n",
    "\n",
    "def generate_anomalous_data(stats, anomaly_x, anomaly_y, reversed_mapping):\n",
    "    anomaly_split = 1000\n",
    "    means = stats[0]\n",
    "    mins = stats[1]\n",
    "    maxs = stats[2]\n",
    "    increase_mag = True\n",
    "    number_anomalies = 200\n",
    "    # now need to randomly select one row of data to to alter, so as to not alter the underlying sequence\n",
    "    anomaly_scale = 1.1\n",
    "    # types of generated anomalies?\n",
    "    # - random\n",
    "    # - intentional anomalies\n",
    "    #   - swap anomalies\n",
    "    #   - activate/deactivate anomalies\n",
    "    # 1. random anomalies\n",
    "    random_anomaly_x = anomaly_x[:anomaly_split, :]\n",
    "    random_actual_y = anomaly_y[:anomaly_split, :]\n",
    "    random_anomaly_y, random_rows = generate_random_anomaly(anomaly_y[:anomaly_split, :], number_anomalies, anomaly_scale, maxs, mins, means,reversed_mapping)\n",
    "\n",
    "    # 2. intentional anomalies\n",
    "    # # 2.1. one simple anomaly is all sensor values = 0\n",
    "    # zero_anomaly_x = anomaly_x[anomaly_split:anomaly_split*2, :]\n",
    "    # zero_anomaly_y, zero_rows = generate_intentional_anomaly(anomaly_y[anomaly_split:anomaly_split*2, :], number_anomalies, anomaly_scale, maxs, mins, \"zero\", reversed_mapping)\n",
    "\n",
    "    # # 2.2 activate some portion of non-active sensors\n",
    "    activate_anomaly_x = anomaly_x[anomaly_split*2:anomaly_split*3, :]\n",
    "    activate_anomaly_y, activate_rows = generate_intentional_anomaly(anomaly_y[anomaly_split*2:anomaly_split*3, :], number_anomalies, anomaly_scale, maxs, mins, means,\"activate\", reversed_mapping)\n",
    "\n",
    "    # deactivate_anomaly_x = anomaly_x[anomaly_split*3:anomaly_split*4, :]\n",
    "    # # # 2.3 de-activate active, activate portion of non-active\n",
    "    # deactivate_anomaly_y, deactivate_rows = generate_intentional_anomaly(anomaly_y[anomaly_split*3:anomaly_split*4, :], number_anomalies, anomaly_scale, maxs, mins, \"deactivate\", reversed_mapping)\n",
    "    return (random_anomaly_x, random_anomaly_y, random_rows, random_actual_y),(activate_anomaly_x, activate_anomaly_y, activate_rows)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def generate_random_anomaly(anomaly_y, number_anomalies, anomaly_scale, maxs, mins, means, reversed_mapping):\n",
    "    row_ids = np.random.choice(anomaly_y.shape[0], size=number_anomalies, replace=False)\n",
    "    random_anomalous_y = pandas.DataFrame(anomaly_y)\n",
    "    random_anomalous_y_copy = random_anomalous_y.copy()\n",
    "    for row_id in row_ids:\n",
    "        new_data = [0.0] * len(random_anomalous_y.columns)\n",
    "        for y in range(len(new_data)):\n",
    "            # if (np.random.ranf() < 0.5):\n",
    "                new_data[y] = means[y] + np.random.uniform(low=random_anomalous_y.loc[row_id][y], high=anomaly_scale * (maxs[y] - mins[y]))\n",
    "        random_anomalous_y.loc[row_id] = new_data\n",
    "    plot_anomalsed_data(row_ids, random_anomalous_y, random_anomalous_y_copy, \"random_anomaly\", reversed_mapping)\n",
    "    return random_anomalous_y.values, row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_intentional_anomaly(anomaly_y, number_anomalies, anomaly_scale, maxs, mins, means, type, reversed_mapping):\n",
    "    row_ids = np.random.choice(anomaly_y.shape[0], size=number_anomalies, replace=False)\n",
    "    intentional_anomalous_y = pandas.DataFrame(anomaly_y)\n",
    "    intentional_anomalous_y_copy = intentional_anomalous_y.copy()\n",
    "    for row_id in row_ids:\n",
    "        new_data = [0.0] * len(intentional_anomalous_y.columns)\n",
    "        for y in range(len(new_data)):\n",
    "            if type==\"deactivate\":\n",
    "                if (intentional_anomalous_y.iloc[row_id][y] != 0.0):\n",
    "                    new_data[y] = np.random.uniform(low=mins[y], high=(maxs[y] - mins[y]))\n",
    "            elif type==\"activate\":\n",
    "                if (intentional_anomalous_y.iloc[row_id][y] == 0.0):\n",
    "                    new_data[y] = means[y] + np.random.uniform(low=mins[y], high= (maxs[y] - mins[y]))\n",
    "        intentional_anomalous_y.loc[row_id] = new_data\n",
    "    plot_anomalsed_data(row_ids, intentional_anomalous_y, intentional_anomalous_y_copy, \"intentional_anomaly\", reversed_mapping)\n",
    "    return intentional_anomalous_y.values, row_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomalsed_data(row_ids, dataset, dataset_copy, type, reversed_mapping):\n",
    "    if (ENABLE_PLOTS):\n",
    "        colors = None\n",
    "        if (DATASET==\"hh101\"):\n",
    "            colors = [\"cornflowerblue\",\"lightsteelblue\",\"mediumblue\",\"blue\",\"slateblue\",\"navy\",\"royalblue\", \"dodgerblue\"]\n",
    "        else:\n",
    "            colors = [\"cornflowerblue\",\"lightsteelblue\",\"mediumblue\",\"blue\",\"slateblue\",\"navy\",\"royalblue\", \"dodgerblue\",\"cyan\"]\n",
    "        fig, (ax1, ax2) = pyplot.subplots(2,1, figsize=(17,12), dpi=300, sharey=True)\n",
    "        # pyplot.setp((ax1,ax2), xticks=[0,20,40,60,80,100],yticks=[0.0, 0.2, 0.4, 0.6, 0.8, 1.0])\n",
    "        ax1.set_xlabel('SEW')\n",
    "        ax1.set_ylabel('Sensor Value')\n",
    "        ax2.set_xlabel('SEW')\n",
    "        ax2.set_ylabel('Sensor Value')\n",
    "        fig.suptitle(\"Normal data vs data with random synthetic anomaly injection\")\n",
    "        dataset_copy.rename(columns=reversed_mapping, inplace=True)\n",
    "        dataset_copy.plot(color=colors, ax=ax1)\n",
    "        dataset.rename(columns=reversed_mapping, inplace=True)\n",
    "        dataset.plot(color=colors, ax=ax2)\n",
    "        for row in row_ids:\n",
    "            ax2.axvspan(row, row, color='red', alpha=0.5)\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(\"data_plots/\" + DATASET + \"/\" + type)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Section 4: Anomaly Detection Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method estimates the likelihood of an anomaly occuring by comparing the predicted value to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomalies(random_anomaly, activate_anomaly, model):\n",
    "    actual_random_anomalies = random_anomaly[2]\n",
    "    errors, r2_s, predictions, df = predict(random_anomaly[0], model, random_anomaly[1])\n",
    "    random_anomaly_scores, random_detected_anomalies = detect_anomaly(random_anomaly, predictions, \"random\", actual_random_anomalies)\n",
    "\n",
    "    actual_activate_anomalies = activate_anomaly[2]\n",
    "    errors, r2_s, predictions, df = predict(activate_anomaly[0], model, activate_anomaly[1])\n",
    "    activate_anomaly_scores, activate_detected_anomalies = detect_anomaly(activate_anomaly, predictions, \"intentional\", actual_activate_anomalies)\n",
    "\n",
    "     # return anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly(anomaly_y, predictions, type, actual):\n",
    "    anomaly_scores = np.empty((predictions.shape[0]))\n",
    "    detected_anomalies = []\n",
    "    correctly_detected_x = []\n",
    "    correctly_detected_y = []\n",
    "    for i, prediction in enumerate(predictions):\n",
    "        anomaly_probability = 0.0\n",
    "        for x, value in enumerate(prediction):\n",
    "            anomaly_probability+=abs(value - anomaly_y[1][i][x])\n",
    "        # print(\"Row \", i, \" probability of anomaly: \", max(anomaly_probability))\n",
    "        anomaly_scores[i] = anomaly_probability / len(prediction)\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    anomaly_scores = anomaly_scores.reshape(-1, 1)\n",
    "    anomaly_scores = min_max_scaler.fit_transform(anomaly_scores)\n",
    "    for i in range(len(anomaly_scores)):\n",
    "        if (anomaly_scores[i] > 0.5):\n",
    "            if i in actual:\n",
    "                correctly_detected_x.append(i)\n",
    "                correctly_detected_y.append(anomaly_scores[i])\n",
    "            else:\n",
    "                detected_anomalies.append(i)\n",
    "    if (ENABLE_PLOTS):\n",
    "        fig, ax1 = pyplot.subplots(figsize=(20,8))\n",
    "        ax1.plot(anomaly_scores, '-p', markevery=actual, c='blue', mfc='red',label='anomaly score', mec='red')\n",
    "        ax1.plot(anomaly_scores, '-p', markevery=correctly_detected_x, c='blue', mfc='green',label='anomaly score', mec='green')\n",
    "        ax1.plot(anomaly_scores, '-p', markevery=detected_anomalies, c='blue', mfc='orange',label='anomaly score', mec='orange')\n",
    "        fig.suptitle(\"Anomaly scores for \" + type + \" anomaly injection\")\n",
    "        fig.savefig(\"anomaly_plots/\" + DATASET + \"/\" + type)\n",
    "    with open(DATASET + '_mse_new.txt', 'a') as f:\n",
    "        f.write(\"Selected ~ SEW size: \" + str(SENSOR_EVENT_WINDOW_SIZE) + \" anomalies = \" + str(len(correctly_detected_x))+ \"\\n\")\n",
    "    return anomaly_scores, detected_anomalies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_anomaly_scores(anomalies, detected, type):\n",
    "    pyplot.plot(anomalies, '-p', markevery=detected, c='blue', mfc='red',label='anomaly score', mec='red', title=\"Anomaly scores for \" + type + \" anomaly injection\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## Section 5: Running the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the code to run the system on data sets 1 and 2 (note these runs use the final model found for the Prediction Module during hyper parameter tuning)\n",
    "\n",
    "1. [HH101](#hh101)\n",
    "2. [HH102](#hh102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hh101'></a>\n",
    "\n",
    "### HH101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted\n",
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh101/extracted/models/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh101/extracted/models/oracle.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh101/extracted/models/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh101/extracted/models/tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x4f4240b20>\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:40:49.885749: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:50.277422: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:50.366432: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:50.566577: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:50.673978: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - ETA: 0s - loss: 0.0493 - mse: 0.0493"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:40:56.728867: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:56.836727: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:40:56.887635: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "444/444 [==============================] - 9s 15ms/step - loss: 0.0493 - mse: 0.0493 - val_loss: 0.0290 - val_mse: 0.0290\n",
      "Epoch 2/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0288 - mse: 0.0288 - val_loss: 0.0287 - val_mse: 0.0287\n",
      "Epoch 3/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0272 - mse: 0.0272 - val_loss: 0.0272 - val_mse: 0.0272\n",
      "Epoch 4/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0264 - mse: 0.0264 - val_loss: 0.0267 - val_mse: 0.0267\n",
      "Epoch 5/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0258 - mse: 0.0258 - val_loss: 0.0260 - val_mse: 0.0260\n",
      "Epoch 6/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0253 - mse: 0.0253 - val_loss: 0.0271 - val_mse: 0.0271\n",
      "Epoch 7/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0246 - mse: 0.0246 - val_loss: 0.0261 - val_mse: 0.0261\n",
      "Epoch 8/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0229 - mse: 0.0229 - val_loss: 0.0247 - val_mse: 0.0247\n",
      "Epoch 9/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0212 - mse: 0.0212 - val_loss: 0.0259 - val_mse: 0.0259\n",
      "Epoch 10/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0205 - mse: 0.0205 - val_loss: 0.0275 - val_mse: 0.0275\n",
      "Epoch 11/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0202 - mse: 0.0202 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 12/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0200 - mse: 0.0200 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 13/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0199 - mse: 0.0199 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 14/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 15/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0197 - mse: 0.0197 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 16/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0196 - mse: 0.0196 - val_loss: 0.0254 - val_mse: 0.0254\n",
      "Epoch 17/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 18/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0195 - mse: 0.0195 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 19/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0255 - val_mse: 0.0255\n",
      "Epoch 20/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 21/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0194 - mse: 0.0194 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 22/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 23/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0193 - mse: 0.0193 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 24/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 25/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 26/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0192 - mse: 0.0192 - val_loss: 0.0253 - val_mse: 0.0253\n",
      "Epoch 27/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0246 - val_mse: 0.0246\n",
      "Epoch 28/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0242 - val_mse: 0.0242\n",
      "Epoch 29/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0191 - mse: 0.0191 - val_loss: 0.0262 - val_mse: 0.0262\n",
      "Epoch 30/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 31/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 32/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0190 - mse: 0.0190 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 33/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0189 - mse: 0.0189 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 34/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0188 - mse: 0.0188 - val_loss: 0.0251 - val_mse: 0.0251\n",
      "Epoch 35/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0187 - mse: 0.0187 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 36/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0186 - mse: 0.0186 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 37/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0249 - val_mse: 0.0249\n",
      "Epoch 38/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0185 - mse: 0.0185 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 39/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 40/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0184 - mse: 0.0184 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 41/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 42/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0183 - mse: 0.0183 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 43/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 44/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 45/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 46/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0182 - mse: 0.0182 - val_loss: 0.0243 - val_mse: 0.0243\n",
      "Epoch 47/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 48/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 49/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 50/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0181 - mse: 0.0181 - val_loss: 0.0252 - val_mse: 0.0252\n",
      "Epoch 51/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 52/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 53/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 54/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 55/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0180 - mse: 0.0180 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 56/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 57/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0248 - val_mse: 0.0248\n",
      "Epoch 58/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 59/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0232 - val_mse: 0.0232\n",
      "Epoch 60/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0223 - val_mse: 0.0223\n",
      "Epoch 61/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0179 - mse: 0.0179 - val_loss: 0.0225 - val_mse: 0.0225\n",
      "Epoch 62/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0250 - val_mse: 0.0250\n",
      "Epoch 63/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0238 - val_mse: 0.0238\n",
      "Epoch 64/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0235 - val_mse: 0.0235\n",
      "Epoch 65/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0178 - mse: 0.0178 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 66/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0244 - val_mse: 0.0244\n",
      "Epoch 67/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 68/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 69/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 70/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0177 - mse: 0.0177 - val_loss: 0.0240 - val_mse: 0.0240\n",
      "Epoch 71/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 72/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 73/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 74/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0176 - mse: 0.0176 - val_loss: 0.0227 - val_mse: 0.0227\n",
      "Epoch 75/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 76/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0237 - val_mse: 0.0237\n",
      "Epoch 77/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0175 - mse: 0.0175 - val_loss: 0.0241 - val_mse: 0.0241\n",
      "Epoch 78/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 79/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 80/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0174 - mse: 0.0174 - val_loss: 0.0239 - val_mse: 0.0239\n",
      "Epoch 81/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 82/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0173 - mse: 0.0173 - val_loss: 0.0245 - val_mse: 0.0245\n",
      "Epoch 83/100\n",
      "444/444 [==============================] - 6s 14ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0230 - val_mse: 0.0230\n",
      "Epoch 84/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0172 - mse: 0.0172 - val_loss: 0.0233 - val_mse: 0.0233\n",
      "Epoch 85/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 86/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0171 - mse: 0.0171 - val_loss: 0.0226 - val_mse: 0.0226\n",
      "Epoch 87/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 88/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0170 - mse: 0.0170 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 89/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0169 - mse: 0.0169 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 90/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 91/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0168 - mse: 0.0168 - val_loss: 0.0231 - val_mse: 0.0231\n",
      "Epoch 92/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0167 - mse: 0.0167 - val_loss: 0.0234 - val_mse: 0.0234\n",
      "Epoch 93/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0228 - val_mse: 0.0228\n",
      "Epoch 94/100\n",
      "444/444 [==============================] - 6s 14ms/step - loss: 0.0166 - mse: 0.0166 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 95/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0165 - mse: 0.0165 - val_loss: 0.0219 - val_mse: 0.0219\n",
      "Epoch 96/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0220 - val_mse: 0.0220\n",
      "Epoch 97/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0164 - mse: 0.0164 - val_loss: 0.0224 - val_mse: 0.0224\n",
      "Epoch 98/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0229 - val_mse: 0.0229\n",
      "Epoch 99/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0163 - mse: 0.0163 - val_loss: 0.0217 - val_mse: 0.0217\n",
      "Epoch 100/100\n",
      "444/444 [==============================] - 6s 13ms/step - loss: 0.0162 - mse: 0.0162 - val_loss: 0.0214 - val_mse: 0.0214\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_60_layer_call_fn, lstm_cell_60_layer_call_and_return_conditional_losses, lstm_cell_61_layer_call_fn, lstm_cell_61_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh101/extracted/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh101/extracted/best_model/assets\n",
      "2022-08-16 21:50:32.879465: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:50:32.998840: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:50:33.122017: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    }
   ],
   "source": [
    "DATASET= \"hh101\"\n",
    "ENABLE_PLOTS = 0\n",
    "import shutil\n",
    "\n",
    "sensor_windows = [49]\n",
    "for i in sensor_windows:\n",
    "    SENSOR_EVENT_WINDOW_SIZE = i\n",
    "    # if os.path.isfile(\"datasets/hh101/extracted_data.csv\"):\n",
    "    #     os.remove(\"datasets/hh101/extracted_data.csv\")\n",
    "    #     os.remove(\"datasets/hh101/final_extracted_dataset.csv\")\n",
    "    #     os.remove(\"datasets/hh101/final_selected_dataset.csv\")\n",
    "    #     os.remove(\"datasets/hh101/normalised_dataset.csv\")\n",
    "    #     os.remove(\"datasets/hh101/selected_data.csv\")\n",
    "    #     shutil.rmtree(\"best_models/hh101/extracted/best_model\")\n",
    "    #     shutil.rmtree(\"best_models/hh101/selected/best_model\")\n",
    "\n",
    "    # Data pre-processing \n",
    "    hh101, hh101_sensor_id_mapping, hh101_reversed_mapping = load_hh101()\n",
    "    hh101, extracted_features = transform_data(hh101, hh101_sensor_id_mapping, create=True) \n",
    "    # Data pre-processing\n",
    "    # # Feature Selection\n",
    "    most_important_features = pca_decomp(hh101, hh101_reversed_mapping)\n",
    "    # # Feature Selection\n",
    "\n",
    "    # # Set up data for prediction module\n",
    "    (hh101_data, plot_data), extracted_data = transform_series_to_supervised(hh101, HH101_PREDICTION_SENSORS, most_important_features, hh101_reversed_mapping, create=True, extracted=extracted_features)\n",
    "    NUMBER_IN_FEATURES = len(most_important_features)\n",
    "    NUMBER_PREDICTIONS = len(HH101_PREDICTION_SENSORS)\n",
    "\n",
    "    if (ENABLE_PLOTS):\n",
    "        plot_normalised_sensor_activations(plot_data, hh101_reversed_mapping)\n",
    "        plot_cleaned_data(hh101, hh101_reversed_mapping)\n",
    "        find_correlations(plot_data, hh101_reversed_mapping)\n",
    "    # train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(hh101_data)\n",
    "    # hh101_selected, hh101_selected_history = get_final_model(train_x, train_y, test_x, test_y)\n",
    "    # random_anomaly, activate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y, hh101_reversed_mapping)\n",
    "    # # # random_anomaly = anomaly_x[:100], anomaly_y[:100], [0], anomaly_y[:100]\n",
    "    # ENABLE_PLOTS = 1\n",
    "    # detect_anomalies(random_anomaly, activate_anomaly,  hh101_selected)\n",
    "    # ENABLE_PLOTS = 0\n",
    "    # hh101_selected_error, hh101_selected_r2s, hh101_selected_predictions, hh101_selected_sensor_errors = predict(anomaly_x, hh101_selected, anomaly_y)\n",
    "\n",
    "    # # Set up data for prediction module\n",
    "\n",
    "\n",
    "    # # Find best hyper-params and train final prediction model, or load best model from file\n",
    "    NUMBER_IN_FEATURES = 6\n",
    "    train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(extracted_data)\n",
    "    # hh101_final_model, hh101_final_model = get_final_model(train_x, train_y, test_x, test_y)\n",
    "    hh101_extracted_model, hh101_extracted_history = get_final_model(train_x, train_y, test_x, test_y, True)\n",
    "    hh101_extracted_error, hh101_extracted_r2s, hh101_extracted_predictions, hh101_extracted_sensor_errors = predict(anomaly_x, hh101_extracted_model, anomaly_y)\n",
    "    # Create various data plots\n",
    "    if (ENABLE_PLOTS):\n",
    "        plot_sensor_mse(hh101_selected_sensor_errors, hh101_extracted_sensor_errors)\n",
    "\n",
    "    # # Create various data plots\n",
    "\n",
    "    with open('hh101_mse_new.txt', 'a') as f:\n",
    "        f.write(\"Extracted ~ SEW size: \" + str(SENSOR_EVENT_WINDOW_SIZE) +\", MSE: \" + str(np.average(hh101_extracted_error)) + \", STD: \" + str(np.std(hh101_extracted_error)) + \"\\n\")\n",
    "        f.write(\"Selected ~ SEW size: \" + str(SENSOR_EVENT_WINDOW_SIZE) +\", MSE: \" + str(np.average(hh101_selected_error)) + \", STD: \" + str(np.std(hh101_selected_error)) + \"\\n\")\n",
    "\n",
    "# # # Find best hyper-params and train final prediction model, or load best model from file\n",
    "\n",
    "# hh101_baseline, hh101_baseline_history = train_baseline(create_baseline(), train_x, train_y, test_x, test_y)\n",
    "# # hh101_final_pred_error, hh101_r2_s, predictions, df = predict(anomaly_x, hh101_final_model, anomaly_y)\n",
    "# # Inject anomalies into hold-out data\n",
    "# # (random_anomaly_x, random_anomaly_y) = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y)\n",
    "# # Inject anomalies into hold-out data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the best model and make predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0    52294\n",
      "1.0       17\n",
      "Name: 0, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "\n",
    "print(hh101[0].value_counts())\n",
    "# from numpy.random import seed\n",
    "# seed(1)\n",
    "# ENABLE_PLOTS = 1\n",
    "\n",
    "random_anomaly, activate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y, hh101_reversed_mapping)\n",
    "# # random_anomaly = anomaly_x[:100], anomaly_y[:100], [0], anomaly_y[:100]\n",
    "detect_anomalies(random_anomaly, activate_anomaly,  final_model)\n",
    "# DATASET=\"hh101\"\n",
    "\n",
    "\n",
    "# predictions = predict(random_anomaly_x, final_model)\n",
    "# anomalies = detect_anomaly(random_anomaly_y, predictions)\n",
    "# detected = []\n",
    "# for i, anomaly in enumerate(anomalies):\n",
    "#     if anomaly > 0.6:\n",
    "#         detected.append(i)\n",
    "# pyplot.plot(anomalies, '-p', markevery=detected, c='blue', mfc='red',label='anomaly score', mec='red')\n",
    "\n",
    "# # plt.plot(range(10))\n",
    "# # plt.axvspan(3, 6, color='red', alpha=0.5)\n",
    "# # plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %load_ext tensorboard\n",
    "# %tensorboard --logdir /Users/christinaspanellis/Desktop/MAC/AAL_ICL/tensorflow/hh102/logs/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cleaned_data(hh101, hh101_reversed_mapping, \"hh101\", \"/cleaned_data.png\")\n",
    "# plot_normalised_sensor_activations(\"hh101\", plot_data, hh101_reversed_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hh102'></a>\n",
    "\n",
    "### HH102"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset...\n",
      "Dataset processed\n",
      "Selecting features...\n",
      "Features selected\n",
      "Transforming data to supervised format...\n",
      "selected\n",
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/selected/models/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/selected/models/oracle.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/selected/models/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/selected/models/tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x2d64cc5e0>\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:52:28.073178: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:28.666206: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:28.801852: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:29.082354: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:29.362371: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - ETA: 0s - loss: 0.0117 - mse: 0.0117"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 21:52:45.865440: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:46.003262: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 21:52:46.058588: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 22s 16ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0047 - val_mse: 0.0047\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0049 - mse: 0.0049 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0048 - mse: 0.0048 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 19s 17ms/step - loss: 0.0047 - mse: 0.0047 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0046 - mse: 0.0046 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 18s 15ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0045 - mse: 0.0045 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0044 - mse: 0.0044 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0043 - mse: 0.0043 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0042 - mse: 0.0042 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0043 - val_mse: 0.0043\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0041 - mse: 0.0041 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0040 - mse: 0.0040 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0044 - val_mse: 0.0044\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0039 - mse: 0.0039 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 18s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 17s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 17s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 17s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 17s 14ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0045 - val_mse: 0.0045\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 17s 15ms/step - loss: 0.0038 - mse: 0.0038 - val_loss: 0.0046 - val_mse: 0.0046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_64_layer_call_fn, lstm_cell_64_layer_call_and_return_conditional_losses, lstm_cell_65_layer_call_fn, lstm_cell_65_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh102/selected/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh102/selected/best_model/assets\n",
      "2022-08-16 22:21:00.769120: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:21:00.926971: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:21:01.178710: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "extracted\n",
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/extracted/models/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/extracted/models/oracle.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/extracted/models/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/extracted/models/tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x2f7135880>\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 22:23:05.741898: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:06.212525: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:06.341041: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:06.643600: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:07.019368: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - ETA: 0s - loss: 0.0220 - mse: 0.0220"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 22:23:22.700787: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:22.885700: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:23:23.130029: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1146/1146 [==============================] - 21s 16ms/step - loss: 0.0220 - mse: 0.0220 - val_loss: 0.0132 - val_mse: 0.0132\n",
      "Epoch 2/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0117 - mse: 0.0117 - val_loss: 0.0118 - val_mse: 0.0118\n",
      "Epoch 3/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0114 - mse: 0.0114 - val_loss: 0.0128 - val_mse: 0.0128\n",
      "Epoch 4/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0112 - mse: 0.0112 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 5/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0110 - mse: 0.0110 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 6/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0107 - mse: 0.0107 - val_loss: 0.0125 - val_mse: 0.0125\n",
      "Epoch 7/100\n",
      "1146/1146 [==============================] - 18s 16ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 8/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0103 - mse: 0.0103 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 9/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0121 - val_mse: 0.0121\n",
      "Epoch 10/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0102 - mse: 0.0102 - val_loss: 0.0122 - val_mse: 0.0122\n",
      "Epoch 11/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0101 - mse: 0.0101 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 12/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0100 - mse: 0.0100 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 13/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 14/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0099 - mse: 0.0099 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 15/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 16/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 17/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0098 - mse: 0.0098 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 18/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0123 - val_mse: 0.0123\n",
      "Epoch 19/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 20/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 21/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0097 - mse: 0.0097 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 22/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 23/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0124 - val_mse: 0.0124\n",
      "Epoch 24/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0096 - mse: 0.0096 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 25/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 26/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 27/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0095 - mse: 0.0095 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 28/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 29/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0094 - mse: 0.0094 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 30/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 31/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 32/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0093 - mse: 0.0093 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 33/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 34/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0092 - mse: 0.0092 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 35/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 36/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 37/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0091 - mse: 0.0091 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 38/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 39/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0090 - mse: 0.0090 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 40/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 41/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0089 - mse: 0.0089 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 42/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 43/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0088 - mse: 0.0088 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 44/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 45/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0087 - mse: 0.0087 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 46/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 47/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 48/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0086 - mse: 0.0086 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 49/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 50/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 51/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0085 - mse: 0.0085 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 52/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 53/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 54/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0084 - mse: 0.0084 - val_loss: 0.0117 - val_mse: 0.0117\n",
      "Epoch 55/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 56/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0107 - val_mse: 0.0107\n",
      "Epoch 57/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 58/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0083 - mse: 0.0083 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 59/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 60/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 61/100\n",
      "1146/1146 [==============================] - 15s 13ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 62/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 63/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0119 - val_mse: 0.0119\n",
      "Epoch 64/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 65/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0082 - mse: 0.0082 - val_loss: 0.0115 - val_mse: 0.0115\n",
      "Epoch 66/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 67/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 68/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 69/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 70/100\n",
      "1146/1146 [==============================] - 15s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0109 - val_mse: 0.0109\n",
      "Epoch 71/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 72/100\n",
      "1146/1146 [==============================] - 15s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0105 - val_mse: 0.0105\n",
      "Epoch 73/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0081 - mse: 0.0081 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 74/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 75/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 76/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 77/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 78/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 79/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0106 - val_mse: 0.0106\n",
      "Epoch 80/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 81/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 82/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 83/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 84/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0116 - val_mse: 0.0116\n",
      "Epoch 85/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0080 - mse: 0.0080 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 86/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 87/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 88/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0113 - val_mse: 0.0113\n",
      "Epoch 89/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 90/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 91/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 92/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0108 - val_mse: 0.0108\n",
      "Epoch 93/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 94/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0120 - val_mse: 0.0120\n",
      "Epoch 95/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0104 - val_mse: 0.0104\n",
      "Epoch 96/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0111 - val_mse: 0.0111\n",
      "Epoch 97/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0114 - val_mse: 0.0114\n",
      "Epoch 98/100\n",
      "1146/1146 [==============================] - 16s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0110 - val_mse: 0.0110\n",
      "Epoch 99/100\n",
      "1146/1146 [==============================] - 15s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0112 - val_mse: 0.0112\n",
      "Epoch 100/100\n",
      "1146/1146 [==============================] - 15s 14ms/step - loss: 0.0079 - mse: 0.0079 - val_loss: 0.0110 - val_mse: 0.0110\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Found untraced functions such as lstm_cell_68_layer_call_fn, lstm_cell_68_layer_call_and_return_conditional_losses, lstm_cell_69_layer_call_fn, lstm_cell_69_layer_call_and_return_conditional_losses while saving (showing 4 of 4). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh102/extracted/best_model/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: best_models/hh102/extracted/best_model/assets\n",
      "2022-08-16 22:49:18.008060: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:49:18.151355: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:49:18.355291: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data transformed\n",
      "Processing dataset...\n",
      "Dataset processed\n",
      "Selecting features...\n",
      "Features selected\n",
      "Transforming data to supervised format...\n",
      "selected\n",
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/selected/models/oracle.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Oracle from existing project tensorflow/hh102/selected/models/oracle.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/selected/models/tuner0.json\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Reloading Tuner from tensorflow/hh102/selected/models/tuner0.json\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Oracle triggered exit\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<keras_tuner.engine.hyperparameters.HyperParameters object at 0x4f3679d90>\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 22:51:55.524421: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:51:55.990425: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:51:56.120135: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:51:56.428830: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:51:56.798024: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - ETA: 0s - loss: 0.0155 - mse: 0.0155"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-08-16 22:52:08.119004: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:52:08.272300: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-08-16 22:52:08.393409: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "751/751 [==============================] - 15s 17ms/step - loss: 0.0155 - mse: 0.0155 - val_loss: 0.0079 - val_mse: 0.0079\n",
      "Epoch 2/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0067 - mse: 0.0067 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 3/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0058 - mse: 0.0058 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 4/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0055 - mse: 0.0055 - val_loss: 0.0053 - val_mse: 0.0053\n",
      "Epoch 5/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0054 - mse: 0.0054 - val_loss: 0.0054 - val_mse: 0.0054\n",
      "Epoch 6/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 7/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0053 - mse: 0.0053 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 8/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0052 - val_mse: 0.0052\n",
      "Epoch 9/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 10/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0052 - mse: 0.0052 - val_loss: 0.0050 - val_mse: 0.0050\n",
      "Epoch 11/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0051 - val_mse: 0.0051\n",
      "Epoch 12/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 13/100\n",
      "751/751 [==============================] - 13s 18ms/step - loss: 0.0051 - mse: 0.0051 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 14/100\n",
      "751/751 [==============================] - 11s 15ms/step - loss: 0.0050 - mse: 0.0050 - val_loss: 0.0049 - val_mse: 0.0049\n",
      "Epoch 15/100\n",
      "751/751 [==============================] - ETA: 0s - loss: 0.0050 - mse: 0.0050"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 60\u001b[0m in \u001b[0;36m<cell line: 4>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=34'>35</a>\u001b[0m NUMBER_PREDICTIONS \u001b[39m=\u001b[39m \u001b[39mlen\u001b[39m(HH102_PREDICTION_SENSORS)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m train_x, train_y, test_x, test_y, anomaly_x, anomaly_y \u001b[39m=\u001b[39m create_train_test_split(hh102_data)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m hh102_selected, hh102_selected_history \u001b[39m=\u001b[39m get_final_model(train_x, train_y, test_x, test_y)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m \u001b[39m# random_anomaly, activate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y, hh102_reversed_mapping)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# # # random_anomaly = anomaly_x[:100], anomaly_y[:100], [0], anomaly_y[:100]\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m \u001b[39m# ENABLE_PLOTS = 1\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m \u001b[39m# detect_anomalies(random_anomaly, activate_anomaly,  hh102_selected)\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39m# ENABLE_PLOTS = 0\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m hh102_selected_error, hh102_selected_r2s, hh102_selected_predictions, hh102_selected_sensor_errors \u001b[39m=\u001b[39m predict(anomaly_x, hh102_selected, anomaly_y)\n",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 60\u001b[0m in \u001b[0;36mget_final_model\u001b[0;34m(train_x, train_y, test_x, test_y, extracted)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=10'>11</a>\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m     tuner \u001b[39m=\u001b[39m tune_model(train_x, train_y, \u001b[39mtype\u001b[39m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m     model, history \u001b[39m=\u001b[39m train_final_model(train_x, train_y, test_x, test_y, tuner, \u001b[39mtype\u001b[39;49m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 60\u001b[0m in \u001b[0;36mtrain_final_model\u001b[0;34m(train_x, train_y, test_x, test_y, tuner, type)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m \u001b[39mprint\u001b[39m(tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m])\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mhypermodel\u001b[39m.\u001b[39mbuild(tuner\u001b[39m.\u001b[39mget_best_hyperparameters()[\u001b[39m0\u001b[39m])\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m history \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39;49mfit(train_x, train_y, epochs\u001b[39m=\u001b[39;49m\u001b[39m100\u001b[39;49m, validation_data\u001b[39m=\u001b[39;49m(test_x, test_y))\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m save_model_and_plot(model, history, \u001b[39mtype\u001b[39m)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#Y112sZmlsZQ%3D%3D?line=20'>21</a>\u001b[0m \u001b[39mreturn\u001b[39;00m model, history\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/keras/engine/training.py:1445\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1431\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mgetattr\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m'\u001b[39m\u001b[39m_eval_data_handler\u001b[39m\u001b[39m'\u001b[39m, \u001b[39mNone\u001b[39;00m) \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m   1432\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_eval_data_handler \u001b[39m=\u001b[39m data_adapter\u001b[39m.\u001b[39mget_data_handler(\n\u001b[1;32m   1433\u001b[0m       x\u001b[39m=\u001b[39mval_x,\n\u001b[1;32m   1434\u001b[0m       y\u001b[39m=\u001b[39mval_y,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1443\u001b[0m       model\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m,\n\u001b[1;32m   1444\u001b[0m       steps_per_execution\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_steps_per_execution)\n\u001b[0;32m-> 1445\u001b[0m val_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mevaluate(\n\u001b[1;32m   1446\u001b[0m     x\u001b[39m=\u001b[39;49mval_x,\n\u001b[1;32m   1447\u001b[0m     y\u001b[39m=\u001b[39;49mval_y,\n\u001b[1;32m   1448\u001b[0m     sample_weight\u001b[39m=\u001b[39;49mval_sample_weight,\n\u001b[1;32m   1449\u001b[0m     batch_size\u001b[39m=\u001b[39;49mvalidation_batch_size \u001b[39mor\u001b[39;49;00m batch_size,\n\u001b[1;32m   1450\u001b[0m     steps\u001b[39m=\u001b[39;49mvalidation_steps,\n\u001b[1;32m   1451\u001b[0m     callbacks\u001b[39m=\u001b[39;49mcallbacks,\n\u001b[1;32m   1452\u001b[0m     max_queue_size\u001b[39m=\u001b[39;49mmax_queue_size,\n\u001b[1;32m   1453\u001b[0m     workers\u001b[39m=\u001b[39;49mworkers,\n\u001b[1;32m   1454\u001b[0m     use_multiprocessing\u001b[39m=\u001b[39;49muse_multiprocessing,\n\u001b[1;32m   1455\u001b[0m     return_dict\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m,\n\u001b[1;32m   1456\u001b[0m     _use_cached_eval_dataset\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n\u001b[1;32m   1457\u001b[0m val_logs \u001b[39m=\u001b[39m {\u001b[39m'\u001b[39m\u001b[39mval_\u001b[39m\u001b[39m'\u001b[39m \u001b[39m+\u001b[39m name: val \u001b[39mfor\u001b[39;00m name, val \u001b[39min\u001b[39;00m val_logs\u001b[39m.\u001b[39mitems()}\n\u001b[1;32m   1458\u001b[0m epoch_logs\u001b[39m.\u001b[39mupdate(val_logs)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/keras/engine/training.py:1756\u001b[0m, in \u001b[0;36mModel.evaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict, **kwargs)\u001b[0m\n\u001b[1;32m   1754\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\u001b[39m'\u001b[39m\u001b[39mtest\u001b[39m\u001b[39m'\u001b[39m, step_num\u001b[39m=\u001b[39mstep, _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1755\u001b[0m   callbacks\u001b[39m.\u001b[39mon_test_batch_begin(step)\n\u001b[0;32m-> 1756\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtest_function(iterator)\n\u001b[1;32m   1757\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1758\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py:954\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    951\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    952\u001b[0m \u001b[39m# In this case we have not created variables on the first call. So we can\u001b[39;00m\n\u001b[1;32m    953\u001b[0m \u001b[39m# run the first trace but we should fail if variables are created.\u001b[39;00m\n\u001b[0;32m--> 954\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateful_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    955\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_created_variables \u001b[39mand\u001b[39;00m \u001b[39mnot\u001b[39;00m ALLOW_DYNAMIC_VARIABLE_CREATION:\n\u001b[1;32m    956\u001b[0m   \u001b[39mraise\u001b[39;00m \u001b[39mValueError\u001b[39;00m(\u001b[39m\"\u001b[39m\u001b[39mCreating variables on a non-first call to a function\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    957\u001b[0m                    \u001b[39m\"\u001b[39m\u001b[39m decorated with tf.function.\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/projnew/lib/python3.8/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "DATASET= \"hh102\"\n",
    "ENABLE_PLOTS = 0\n",
    "sensor_windows = [19, 29, 39, 49]\n",
    "for i in sensor_windows:\n",
    "    SENSOR_EVENT_WINDOW_SIZE = i\n",
    "    if os.path.isfile(\"datasets/hh102/extracted_data.csv\"):\n",
    "        os.remove(\"datasets/hh102/extracted_data.csv\")\n",
    "        os.remove(\"datasets/hh102/final_extracted_dataset.csv\")\n",
    "        os.remove(\"datasets/hh102/final_selected_dataset.csv\")\n",
    "        os.remove(\"datasets/hh102/normalised_dataset.csv\")\n",
    "        os.remove(\"datasets/hh102/selected_data.csv\")\n",
    "        shutil.rmtree(\"best_models/hh102/extracted/best_model\")\n",
    "        shutil.rmtree(\"best_models/hh102/selected/best_model\")\n",
    "\n",
    "    # Data pre-processing \n",
    "    print(\"Processing dataset...\")\n",
    "    hh102, hh102_sensor_id_mapping, hh102_reversed_mapping = load_hh102()\n",
    "    hh102, extracted_features = transform_data(hh102, hh102_sensor_id_mapping, create=True) \n",
    "\n",
    "    print(\"Dataset processed\")\n",
    "    # Data pre-processing\n",
    "\n",
    "    # Feature Selection\n",
    "    print(\"Selecting features...\")\n",
    "\n",
    "    most_important_features = pca_decomp(hh102, hh102_reversed_mapping)\n",
    "    # Feature Selection\n",
    "    print(\"Features selected\")\n",
    "\n",
    "    # Set up data for prediction module\n",
    "    print(\"Transforming data to supervised format...\")\n",
    "    (hh102_data, plot_data), extracted_data = transform_series_to_supervised(hh102, HH102_PREDICTION_SENSORS, most_important_features, hh102_reversed_mapping, create=True, extracted=extracted_features)\n",
    "\n",
    "    NUMBER_IN_FEATURES = len(most_important_features)\n",
    "    NUMBER_PREDICTIONS = len(HH102_PREDICTION_SENSORS)\n",
    "\n",
    "    train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(hh102_data)\n",
    "    hh102_selected, hh102_selected_history = get_final_model(train_x, train_y, test_x, test_y)\n",
    "    # random_anomaly, activate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y, hh102_reversed_mapping)\n",
    "    # # # random_anomaly = anomaly_x[:100], anomaly_y[:100], [0], anomaly_y[:100]\n",
    "    # ENABLE_PLOTS = 1\n",
    "    # detect_anomalies(random_anomaly, activate_anomaly,  hh102_selected)\n",
    "    # ENABLE_PLOTS = 0\n",
    "    hh102_selected_error, hh102_selected_r2s, hh102_selected_predictions, hh102_selected_sensor_errors = predict(anomaly_x, hh102_selected, anomaly_y)\n",
    "    # Set up data for prediction module\n",
    "\n",
    "    NUMBER_IN_FEATURES = 6\n",
    "    train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(extracted_data)\n",
    "    hh102_extracted_model, hh102_extracted_history = get_final_model(train_x, train_y, test_x, test_y, True)\n",
    "    hh102_extracted_error, hh102_extracted_r2s, hh102_extracted_predictions, hh102_extracted_sensor_errors = predict(anomaly_x, hh102_extracted_model, anomaly_y)\n",
    "\n",
    "    print(\"Data transformed\")\n",
    "    with open('hh102_mse_new.txt', 'a') as f:\n",
    "        f.write(\"Extracted ~ SEW size: \" + str(SENSOR_EVENT_WINDOW_SIZE) +\", MSE: \" + str(np.average(hh102_extracted_error)) + \", STD: \" + str(np.std(hh102_extracted_error)) + \"\\n\")\n",
    "        f.write(\"Selected ~ SEW size: \" + str(SENSOR_EVENT_WINDOW_SIZE) +\", MSE: \" + str(np.average(hh102_selected_error)) + \", STD: \" + str(np.std(hh102_selected_error)) + \"\\n\")\n",
    "\n",
    "    # Create various data plots\n",
    "    if (ENABLE_PLOTS):\n",
    "        print(\"Plotting graphs..\")\n",
    "        plot_normalised_sensor_activations(plot_data, hh102_reversed_mapping)\n",
    "        plot_cleaned_data(hh102, hh102_reversed_mapping)\n",
    "        find_correlations(plot_data, hh102_reversed_mapping)\n",
    "        plot_sensor_mse(hh101_selected_sensor_errors, hh101_extracted_sensor_errors)\n",
    "\n",
    "        print(\"Graphs plotted\")\n",
    "# Create various data plots\n",
    "# # plot_sensor_mse(hh102_selected_sensor_errors, hh102_extracted_sensor_errors)\n",
    "# # plot_final_mse(hh101_selected_error, hh101_extracted_error, hh102_selected_error, hh102_extracted_error)\n",
    "\n",
    "\n",
    "# # Find best hyper-params and train final prediction model, or load best model from file\n",
    "# # hh102_final_model, hh102_history = get_final_model(train_x, train_y, test_x, test_y)\n",
    "# # Find best hyper-params and train final prediction model, xor load best model from file\n",
    "# # hh102_final_pred_error, hh101_r2_s, predictions, df = predict(anomaly_x, hh102_final_model, anomaly_y)\n",
    "\n",
    "\n",
    "# # # Set up data for prediction module\n",
    "\n",
    "\n",
    "# # Find best hyper-params and train final prediction model, or load best model from file\n",
    "\n",
    "# Inject anomalies into hold-out data\n",
    "# random_anomaly, zero_anomaly, activate_anomaly, deactivate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y)\n",
    "# Inject anomalies into hold-out data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell will create various plots of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# pyplot.plot(hh102_selected_history.history['loss'], label='Selected Loss')\n",
    "# pyplot.plot(hh102_selected_history.history['val_loss'], label='Selected Validation Loss')\n",
    "# pyplot.plot(hh102_extracted_history.history['loss'], label='Extracted loss')\n",
    "# pyplot.plot(hh102_extracted_history.history['val_loss'], label='Extrated Validation Loss')\n",
    "# pyplot.xlabel(\"Epochs\")\n",
    "# pyplot.ylabel(\"Loss\")\n",
    "# pyplot.title(\"Training and validation loss of \"+ DATASET.upper() +\" models.\")\n",
    "# pyplot.tight_layout()\n",
    "# pyplot.legend()\n",
    "# pyplot.savefig(\"best_models/\"+ DATASET +\"/best_model\")\n",
    "# hh102_final_pred_error = hh102_final_pred_error[:len(hh101_final_pred_error)]\n",
    "# x = list(range(0,len(hh102_final_pred_error)))\n",
    "# # pyplot.plot(x,hh101_final_pred_error, label='HH101 prediction error', linewidth=2)\n",
    "# pyplot.figure(figsize=(20,6))\n",
    "# pyplot.plot(x,hh102_final_pred_error ,label='HH102 prediction error', linewidth=0.5)\n",
    "# pyplot.xlabel(\"SEW\")\n",
    "# pyplot.ylabel(\"MSE\")\n",
    "# pyplot.title(\"Prediction error of the HH101 and HH102 final models.\")\n",
    "# pyplot.tight_layout()\n",
    "# pyplot.legend()\n",
    "# pyplot.savefig(\"best_models/final_errors\")\n",
    "# random_anomaly, activate_anomaly = generate_anomalous_data(get_stats(np.row_stack((test_y, train_y, anomaly_y))), anomaly_x, anomaly_y, hh102_reversed_mapping)\n",
    "# # random_anomaly = anomaly_x[:100], anomaly_y[:100], [0], anomaly_y[:100]\n",
    "# detect_anomalies(random_anomaly, activate_anomaly,  final_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df = pandas.DataFrame({\"HH101\": hh101_error, \"HH102\": hh102_error[:len(hh101_error)]})\n",
    "# # pyplot.boxplot([hh101_error, hh102_error], whis=(5,90), labels=[\"HH101\", \"HH102\"], meanline=True, showfliers=False)\n",
    "# b = sns.boxplot(data = df, showfliers=False, whis=1.5)\n",
    "# b.set_ylabel(\"MSE\", fontsize=12)\n",
    "# b.set_xlabel(\"Data set\", fontsize=12)\n",
    "# b.set_title(\"MSE of final prediction models\", fontsize=14)\n",
    "# # # b.set_yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.14, 0.16])\n",
    "# sns.set(rc = {'figure.figsize':(15,12)})\n",
    "# f = b.get_figure()\n",
    "# f.savefig(\"data_plots/final_mse\")\n",
    "# sns.despine(offset = 5, trim = True)\n",
    "\n",
    "# pyplot.xticks([])\n",
    "# b = sns.boxplot(data = sensor_errors, showfliers=False, whis=1.5)\n",
    "# b.set_ylabel(\"MSE\", fontsize=12)\n",
    "# b.set_xlabel(\"Sensor\", fontsize=12)\n",
    "# b.set_title(\"MSE per sensor in \" + DATASET +\" model\", fontsize=14)\n",
    "# # # b.set_yticks([0.00, 0.01, 0.02, 0.03, 0.04, 0.05, 0.06, 0.07, 0.08, 0.09, 0.1, 0.12, 0.14, 0.16])\n",
    "# sns.set(rc = {'figure.figsize':(15,12)})\n",
    "# f = b.get_figure()\n",
    "# f.savefig(\"data_plots/\" + DATASET+\"/sensor_mse\")\n",
    "# sns.despine(offset = 5, trim = True)\n",
    "# print(len(hh102_error[0]))\n",
    "# dataset = pandas.DataFrame({'y': anomaly_y, 'y_pred': hh102_predictions}, columns=['y', 'y_pred]'])\n",
    "\n",
    "# g = sns.lmplot(x = 'y', y='y_pred',data= dataset, hue='tag')\n",
    "# g.fig.suptitle('True Vs Pred', y=1.02)\n",
    "# g.set_axis_labels('y_true', 'y_pred')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('projnew')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "af2f049532c2b869fa3cc4e68ab09f7dac73e40ec50551a74fb31a492660dfa5"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
