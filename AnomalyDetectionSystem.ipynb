{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# MSc Individual Project: Anomaly Detection for Assisted Independent Living\n",
    "\n",
    "Author: Christina Spanellis\n",
    " \n",
    "Sections 1-4 of this notebook define the necessary method definitions and constants for this project.\n",
    "\n",
    "Section 5 contains code to build and test the system\n",
    "\n",
    "## Sections\n",
    "### 1. [Data preparation and pre-processing](#section1)\n",
    "### 2. [Anomalous Data Generation Module](#section2)\n",
    "### 3. [Prediction Module](#section3)\n",
    "### 4. [Anomaly Detection Module](#section4)\n",
    "### 5. [Running the system](#section5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages for the project\n",
    "from pandas import read_csv\n",
    "from datetime import datetime\n",
    "from matplotlib import pyplot\n",
    "from pandas import DataFrame\n",
    "from pandas import concat\n",
    "import pandas\n",
    "from sklearn import datasets\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from keras.models import Sequential\n",
    "from keras import callbacks\n",
    "from keras.layers import Dense\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dropout\n",
    "import keras_tuner as kt\n",
    "import numpy as np\n",
    "from keras.metrics import mean_squared_error\n",
    "from numpy import sqrt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section1'></a>\n",
    "## Section 1: Data preparation and pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two different data sets had to be cleaned and prepared to be in a suitable format for the prediction module. \n",
    "\n",
    "Data set 1: CASAS HH101\n",
    "\n",
    "Data set 2: CASAS HH102\n",
    "\n",
    "The below definitions define the constants and logic needed for loading and pre-processing. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CONSTANTS AND GLOBALS DEFINITION\n",
    "\n",
    "SENSOR_EVENT_WINDOW_SIZE = 19\n",
    "HH101_PREDICTION_SENSORS = [\"M003\", \"LS002\", \"M004\", \"M005\", \"LS005\", \"MA015\", \"M012\", \"M010\"]\n",
    "HH102_PREDICTION_SENSORS = [\"M007\", \"T105\", \"LS008\", \"M004\", \"M002\", \"LS010\", \"MA009\", \"M018\", \"LS002\"]\n",
    "train_x = None\n",
    "NUMBER_IN_FEATURES = None\n",
    "NUMBER_PREDICTIONS = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the hh101 data set\n",
    "def load_hh101():\n",
    "    # load the data set\n",
    "    hh101 = read_csv('datasets/hh101/hh101.csv', names=[\"Sensor\",1,2,\"Value\",\"Type\"])\n",
    "    hh101.drop(columns={1,2,\"Type\"}, inplace=True)\n",
    "    # replace string values and drop unwanted sensor readings\n",
    "    hh101 = hh101[hh101[\"Sensor\"].str.contains(\"BAT\") == False]\n",
    "    # hh101 = hh101[hh101[\"Sensor\"] != \"D001\"]\n",
    "    # hh101 = hh101[hh101[\"Sensor\"] != \"LS010\"]\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"ON\" : 1.0, \"OFF\" : 0.0})\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"ABSENT\" : 1.0, \"PRESENT\" : 0.0})\n",
    "    hh101[\"Value\"] = hh101[\"Value\"].replace({\"OPEN\" : 1.0, \"CLOSE\" : 0.0})\n",
    "    # creating a mapping of the sensor names to keep track of them\n",
    "    count = 0\n",
    "    hh101_sensor_id_mapping = {}\n",
    "    for sensor in hh101[\"Sensor\"].values:\n",
    "        if sensor not in hh101_sensor_id_mapping:\n",
    "            hh101_sensor_id_mapping[sensor] = count\n",
    "            count+=1\n",
    "    hh101_reversed_mapping = {y: x for x, y in hh101_sensor_id_mapping.items()}\n",
    "    return (hh101, hh101_sensor_id_mapping, hh101_reversed_mapping)\n",
    "\n",
    "# load the hh102 dataset \n",
    "def load_hh102():\n",
    "    # load the data set\n",
    "    hh102 = read_csv('datasets/hh102/hh102.csv', names=[\"Sensor\",1,2,\"Value\",\"Type\"])\n",
    "    hh102.drop(columns={1,2,\"Type\"}, inplace=True)\n",
    "    # replace string values and drop unwanted sensor readings\n",
    "    hh102 = hh102[hh102[\"Sensor\"].str.contains(\"BAT\") == False]\n",
    "    # hh102 = hh102[hh102[\"Sensor\"] != \"D001\"]\n",
    "    # hh102 = hh102[hh102[\"Sensor\"] != \"LS010\"]\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"ON\" : 1.0, \"OFF\" : 0.0})\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"ABSENT\" : 1.0, \"PRESENT\" : 0.0})\n",
    "    hh102[\"Value\"] = hh102[\"Value\"].replace({\"OPEN\" : 1.0, \"CLOSE\" : 0.0})\n",
    "    # creating a mapping of the sensor names to keep track of them\n",
    "    count = 0\n",
    "    hh102_sensor_id_mapping = {}\n",
    "    for sensor in hh102[\"Sensor\"].values:\n",
    "        if sensor not in hh102_sensor_id_mapping:\n",
    "            hh102_sensor_id_mapping[sensor] = count\n",
    "            count+=1\n",
    "    hh102_reversed_mapping = {y: x for x, y in hh102_sensor_id_mapping.items()}\n",
    "    return (hh102, hh102_sensor_id_mapping, hh102_reversed_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def remove_sensors(dataset, sensors, mapping):\n",
    "    for i in range (len(sensors)):\n",
    "        sensors[i] = mapping[sensors[i]]\n",
    "    return dataset.drop(columns=sensors)\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "def pca_decomp(dataset):\n",
    "    pca = PCA(n_components=10)\n",
    "    pca.fit_transform(dataset)\n",
    "    n_pcs= pca.n_components_ # get number of component\n",
    "    # get the index of the most important feature on EACH component\n",
    "    most_important = [np.abs(pca.components_[i]).argmax() for i in range(n_pcs)]\n",
    "    initial_feature_names = dataset.columns\n",
    "    # get the most important feature names\n",
    "    most_important_features = [initial_feature_names[most_important[i]] for i in range(n_pcs)]\n",
    "    # dataset = dataset[most_important_features]\n",
    "    return most_important_features\n",
    "    # quasi_constant = [col for col in dataset.columns if col not in selected.get_feature_names_out()]\n",
    "    # print(len(quasi_constant))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method transforms the data set into a format where the columns represent the various sensor values and segment the data into 20 event sensor windows.\n",
    "\n",
    "This means that each row in the data set represents the activations for the previous 20 sensor event activations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_data(dataset, sensor_id_mapping):\n",
    "    data = []\n",
    "    starting_date_time = datetime.strptime(dataset.index[0], '%Y-%m-%d %H:%M:%S.%f')\n",
    "    starting_date_time = starting_date_time.replace(microsecond=0)\n",
    "    sensor_vals = [0.0] * len(sensor_id_mapping)\n",
    "    event_count = 0 ## counter used to segment the data into sensor event windows\n",
    "    for i, row in dataset.iterrows():\n",
    "        curr_date_time =  datetime.strptime(i, '%Y-%m-%d %H:%M:%S.%f')\n",
    "        curr_date_time = curr_date_time.replace(microsecond=0)\n",
    "        if (event_count >= SENSOR_EVENT_WINDOW_SIZE):\n",
    "            values = [starting_date_time.strftime(\"%m-%d-%Y %H:%M:%S\")]\n",
    "            values.extend(sensor_vals)\n",
    "            data.append(values)\n",
    "            starting_date_time = curr_date_time\n",
    "            sensor_vals = [0.0] * len(sensor_id_mapping)\n",
    "            event_count = 0\n",
    "        event_count +=1\n",
    "        if \"D\" in row[\"Sensor\"] or \"M\" in row[\"Sensor\"]:\n",
    "            if sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] == 0:\n",
    "                sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] = 1\n",
    "            else:\n",
    "                sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] += 1\n",
    "        else:\n",
    "                sensor_vals[sensor_id_mapping[row[\"Sensor\"]]] = row[\"Value\"]\n",
    "\n",
    "    columns = [i for i in range (0,len(sensor_id_mapping))]\n",
    "    final_columns = [\"Time\"]\n",
    "    final_columns.extend(columns)\n",
    "    # set the index of the dataframe to be the time column\n",
    "    new_data = pandas.DataFrame.from_records(data, columns=final_columns)\n",
    "    new_data[\"Time\"] = pandas.to_datetime(new_data[\"Time\"], format='%m-%d-%Y %H:%M:%S')\n",
    "    new_data = new_data.set_index(\"Time\")\n",
    "    return new_data   \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method plots all the data (non-normalised) after formatting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_cleaned_data(data, reversed_mapping, name, path):\n",
    "    changed_legend = data.rename(columns = reversed_mapping)\n",
    "    ax = changed_legend.plot(subplots=True, figsize=(40,40), title=name.upper() + \" sensor values over time.\", ylabel=\"Sensor Value\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(\"data_plots/\" + name + path, format=\"png\", dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method transforms the series into a format suitable for a supervised learning problem.\n",
    "\n",
    "Eg. [Sensor1(t-1), Sensor2(t-1), Sensor1(t), Sensor2(t)]\n",
    "\n",
    "Where readings at t-1 represent the sensor activations for the period before the activations at t.\n",
    "\n",
    "Sensor activations at time t then become the ground truth values for activations at t-1 in the prediction module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_series_to_supervised(new_data, prediction_sensors, important_features, reversed_mapping):\n",
    "    df = new_data.copy()\n",
    "    # print(df)\n",
    "    # print(df)\n",
    "    # scale values\n",
    "    values = df.values\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_values = min_max_scaler.fit_transform(values)\n",
    "    normalized_df = pandas.DataFrame(scaled_values)\n",
    "    n_vars = len(normalized_df.columns)\n",
    "    time_Series = normalized_df.copy().set_index(df.index)\n",
    "    cols, names = list(), list()\n",
    "    # input sequence (t-n, ... t-1)\n",
    "    for i in range(1, 0, -1):\n",
    "        sequence = normalized_df.shift(i)\n",
    "        sequence = sequence.rename(columns=reversed_mapping)\n",
    "        sequence = sequence[important_features]\n",
    "        cols.append(sequence)\n",
    "        names += [('var%s(t-%d)' % (label, i)) for label in sequence.columns]\n",
    "    # forecast sequence (t, t+1, ... t+n)\n",
    "    for i in range(0, 1):\n",
    "        sequence = normalized_df.shift(-i)\n",
    "        sequence = sequence.rename(columns=reversed_mapping)\n",
    "        sequence = sequence[prediction_sensors]\n",
    "        cols.append(sequence.shift(-i))\n",
    "        names += [('var%s(t)' % (label)) for label in sequence.columns]\n",
    "    # put it all together\n",
    "    agg = concat(cols, axis=1)\n",
    "    agg.columns = names\n",
    "    # drop rows with NaN values\n",
    "    agg.dropna(inplace=True)\n",
    "    return (agg, normalized_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method plots the activations for the sensors in the data set, grouped into figures by sensor type."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_normalised_sensor_activations(dataset_name, normalized_df, reversed_mapping):\n",
    "    changed_legend = normalized_df.rename(columns = reversed_mapping)\n",
    "    doors =[]\n",
    "    lights = []\n",
    "    temp = []\n",
    "    motion = []\n",
    "    for key in reversed_mapping:\n",
    "        if \"D\" in reversed_mapping[key]:\n",
    "            doors.append(key)\n",
    "        elif \"L\" in reversed_mapping[key]:\n",
    "            lights.append(key)\n",
    "        elif \"T1\" in reversed_mapping[key]:\n",
    "            temp.append(key)\n",
    "        else:\n",
    "            motion.append(key)\n",
    "    sensors = [doors, lights, temp, motion]\n",
    "    names = [\"Door Sensors\", \"Light Sensors\", \"Temperature Sensors\", \"Motion Sensors\"]\n",
    "    for i, sensor in enumerate(sensors):\n",
    "        fig, axs = None, None\n",
    "        if len(sensor) % 2 == 0 or len(sensor) > 10 :\n",
    "            fig, axs = pyplot.subplots(int(len(sensor) / 2),2,  sharex=True, sharey=True,figsize=(10,10))\n",
    "        else:\n",
    "            fig, axs = pyplot.subplots(len(sensor),1, figsize=(10,10))\n",
    "        count = 0\n",
    "        for ax in axs.flat:\n",
    "            ax.plot(changed_legend[reversed_mapping[sensor[count]]])\n",
    "            ax.set_title(reversed_mapping[sensor[count]])\n",
    "            ax.set_xticks([0, 10000, 20000, 30000, 40000, 50000])\n",
    "            count += 1\n",
    "        for ax in axs.flat:\n",
    "            ax.label_outer()\n",
    "        fig.suptitle(names[i])\n",
    "        fig.supxlabel(\"Instance\")\n",
    "        fig.supylabel(\"Sensor Value\")\n",
    "        pyplot.tight_layout()\n",
    "        pyplot.savefig(\"data_plots/\" + dataset_name + \"/\" +names[i],dpi=1200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Discover the features with the highest correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def find_correlations(dataset, path, name, reversed_mapping):\n",
    "    min_max_scaler = MinMaxScaler()\n",
    "    scaled_values = min_max_scaler.fit_transform(dataset.values)\n",
    "    normalized_df = pandas.DataFrame(scaled_values)\n",
    "    normalized_df = normalized_df.rename(columns = reversed_mapping)\n",
    "    corrmat = normalized_df.corr(method='pearson', min_periods=100)\n",
    "    corrmat = np.abs(corrmat)\n",
    "    sns.set(context=\"paper\", font=\"monospace\")\n",
    "    f, ax = plt.subplots(figsize=(12, 9))\n",
    "    sns.heatmap(corrmat, vmax=0.8, square=True, xticklabels = True, yticklabels = True)\n",
    "    pyplot.title(name + \" Pearson correlation values between sensors (absolute valued).\")\n",
    "    pyplot.xlabel(\"Sensor ID\")\n",
    "    pyplot.ylabel(\"Sensor ID\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.savefig(\"data_plots/\" + path + name)\n",
    "    triangluar_corrmat = np.triu(corrmat, k=1)\n",
    "    values = np.where(triangluar_corrmat >= 0.6)\n",
    "    values = list(zip(values[0], values[1]))\n",
    "    for x in range (len(values)):\n",
    "        values[x] = (reversed_mapping[values[x][0]], reversed_mapping[values[x][1]], triangluar_corrmat[values[x][0]][values[x][1]])\n",
    "    return values \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data needs to be separated out into training (70%), testing (20%) and anomalous portions (10%).\n",
    "\n",
    "The anomalous portion of the data is held back for synthetic anomaly injection to later be used to test the AD system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_train_test_split(dataset):\n",
    "    values = dataset.values\n",
    "    train_split = int(0.7 * len(values))\n",
    "    anomaly_split = int(0.9 * len(values))\n",
    "    train = values[:train_split, :]\n",
    "    test = values[train_split:anomaly_split, :]\n",
    "    anomalies = values[anomaly_split:, :]\n",
    "\n",
    "    train_x, train_y = train[:, :NUMBER_IN_FEATURES], train[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    test_x, test_y = test[:, :NUMBER_IN_FEATURES], test[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    anomaly_x, anomaly_y = anomalies[:, :NUMBER_IN_FEATURES], anomalies[:, NUMBER_IN_FEATURES:]\n",
    "\n",
    "    train_x = np.asarray(train_x).astype(np.float32)\n",
    "    train_y = np.asarray(train_y).astype(np.float32)\n",
    "    test_y = np.asarray(test_y).astype(np.float32)\n",
    "    test_x = np.asarray(test_x).astype(np.float32)\n",
    "    train_x = train_x.reshape((train_x.shape[0], 1, train_x.shape[1]))\n",
    "    test_x = test_x.reshape((test_x.shape[0], 1, test_x.shape[1]))\n",
    "\n",
    "    return (train_x, train_y, test_x, test_y, anomaly_x, anomaly_y)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section3'></a>\n",
    "\n",
    "## Section 3: Prediction Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains the logic to train models for the Prediction Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A method to save trained models and plot their loss (used for experimentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "def save_model_and_plot(model, filename, history):\n",
    "    pickle.dump(model, open(\"prediction_models/\" +filename +\".sav\", 'wb'))\n",
    "    pyplot.plot(history.history['loss'], label='Loss')\n",
    "    pyplot.plot(history.history['val_loss'], label='Validation Loss')\n",
    "    pyplot.xlabel(\"Epochs\")\n",
    "    pyplot.ylabel(\"Loss\")\n",
    "    pyplot.title(\"Loss and Validation loss of prediction model before tuning.\")\n",
    "    pyplot.tight_layout()\n",
    "    pyplot.legend()\n",
    "    filename = \"prediction_plots/\" + filename\n",
    "    pyplot.savefig(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This creates a model suitable for hyper parameter tuning in in keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_model(hp):\n",
    "    # design network\n",
    "    model = Sequential()\n",
    "    model.add(LSTM(hp.Int('input_unit', min_value = 50, max_value = 600, step = 50), input_shape=(train_x.shape[1], train_x.shape[2]), return_sequences = True))\n",
    "    for i in range (hp.Int('n_layers', 1, 3)):\n",
    "            model.add(LSTM(hp.Int(f'lstm_{i}_units', min_value = 50, max_value = 600, step = 50), return_sequences = True))\n",
    "    model.add(LSTM(hp.Int(f'final_lstm_layer', min_value = 50, max_value = 600, step = 50)))\n",
    "    model.add(Dropout(hp.Float('Dropout_rate',min_value=0,max_value=0.5,step=0.1)))\n",
    "    model.add(Dense(NUMBER_PREDICTIONS, activation = hp.Choice('dense_activation', values=['relu', 'sigmoid'],default='relu')))\n",
    "    model.compile(loss='mean_squared_error', optimizer='adam', metrics = ['mse'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create and use the keras tuner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tune_model(x_train, y_train):\n",
    "\n",
    "    tuner = kt.RandomSearch(\n",
    "        build_model,\n",
    "        objective='mse',\n",
    "        max_trials=12,\n",
    "        executions_per_trial=1,\n",
    "        directory=\"/tmp/tb\",\n",
    "        overwrite = True\n",
    "\n",
    "    )\n",
    "    tuner.search(\n",
    "        x_train,\n",
    "        y_train,\n",
    "        batch_size = 64,\n",
    "        validation_split=0.2,\n",
    "        epochs = 100,\n",
    "        callbacks=[callbacks.TensorBoard(\"/tmp/tb_logs\")],\n",
    "\n",
    "    )\n",
    "    best_model = tuner.get_best_models(num_models=1)[0]\n",
    "    return best_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from numpy import concatenate\n",
    "# from math import sqrt\n",
    "# from sklearn.metrics import mean_squared_error\n",
    "\n",
    "\n",
    "# # make a prediction\n",
    "# yhat = model.predict(test_x)\n",
    "# test_x = test_x.reshape((test_x.shape[0], features))\n",
    "# print(test_x)\n",
    "# print(yhat)\n",
    "# # # calculate RMSE\n",
    "# rmse = sqrt(mean_squared_error(test_y, yhat))\n",
    "# print('Test RMSE: %.3f' % rmse)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section2'></a>\n",
    "## Section 2: Anomamlous Data Generation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following section contains the logic for the Anomalous Data Generation Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method takes the test data and inserts anomalies into a specified fraction of the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try generating some anomalous data\n",
    "# So decide on the number of anomalous samples.. for example 10\n",
    "# Then just affect one 20 event sensor window\n",
    "# One idea is to just scale data to be bigger than 1, in theory this is an anomaly but isn't really in the expected range of input...\n",
    "# https://github.com/tirthajyoti/Synthetic-data-gen/blob/master/Notebooks/Time%20series%20synthesis%20with%20anomaly.ipynb\n",
    "\n",
    " # retrieves the mean, min and max of the different features in the data set\n",
    "def get_stats(dataset):\n",
    "    return (dataset.mean(), dataset.min(), dataset.max())\n",
    "\n",
    "def generate_anomalous_data(stats, anomaly_y, number_features):\n",
    "    anomaly_frac = 0.2\n",
    "    anomaly_scale = 1.2\n",
    "    one_sided = False\n",
    "    means = stats[0]\n",
    "    mins = stats[1]\n",
    "    maxs = stats[2]\n",
    "\n",
    "\n",
    "    # rows_to_be_modified = new_arr.sample(frac=0.2).values # select (no_anomalies) rows from the data set\n",
    "    # no_anomalies = len(rows_to_be_modified)\n",
    "    \n",
    "    # now need to randomly select one row of datano to alter, so as to not alter the underlying sequence\n",
    "    anomalous_y = anomaly_y\n",
    "    for i, row in enumerate(anomalous_y):\n",
    "        for y, data_point in enumerate(row):\n",
    "            anomalous_y[i][y] = means[y] + np.random.uniform(low=mins[y], high=anomaly_scale * (maxs[y] - mins[y]))\n",
    "\n",
    "    return anomalous_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section4'></a>\n",
    "## Section 4: Anomaly Detection Module"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This method estimates the likelihood of an anomaly occuring by comparing the predicted value to the ground truth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detect_anomaly(anomaly_x, anomaly_y, predictions):\n",
    "    anomaly_free_x_values = anomaly_x\n",
    "    anomaly_inserted_y_vales = anomaly_y\n",
    "    \n",
    "    for i, prediction in enumerate(predictions):\n",
    "        anomaly_probability = 0.0\n",
    "        for x, value in enumerate(prediction):\n",
    "            anomaly_probability += abs(value - anomaly_inserted_y_vales[i][x])\n",
    "        print(\"Probability of anomaly: \", anomaly_probability / len(prediction))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='section5'></a>\n",
    "## Section 5: Running the system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section contains the code to run the system on data sets 1 and 2 (note these runs use the final model found for the Prediction Module during hyper parameter tuning)\n",
    "\n",
    "1. [HH101](#hh101)\n",
    "2. [HH102](#hh102)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hh101'></a>\n",
    "\n",
    "### HH101 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh101, hh101_sensor_id_mapping, hh101_reversed_mapping = load_hh101()\n",
    "hh101_drop = [\"D002\", \"MA016\", \"LS010\", \"LS009\", \"LS013\", \"LS006\", \"M006\", \"MA013\", \"LS015\",\"T101\", \"T102\", \"T103\", \"T104\", \"T105\"]\n",
    "hh101 = transform_data(hh101, hh101_sensor_id_mapping)\n",
    "hh101_removed = remove_sensors(hh101, hh101_drop, hh101_sensor_id_mapping)\n",
    "most_important_features = pca_decomp(hh101_removed)\n",
    "for i, feature in enumerate(most_important_features):\n",
    "    most_important_features[i] = hh101_reversed_mapping[feature]\n",
    "hh101_data, plot_data = transform_series_to_supervised(hh101, HH101_PREDICTION_SENSORS, most_important_features, hh101_reversed_mapping)\n",
    "NUMBER_IN_FEATURES = len(most_important_features)\n",
    "NUMBER_PREDICTIONS = len(HH101_PREDICTION_SENSORS)\n",
    "train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(hh101_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "input_unit        |500               |?                 \n",
      "n_layers          |2                 |?                 \n",
      "lstm_0_units      |450               |?                 \n",
      "final_lstm_layer  |300               |?                 \n",
      "Dropout_rate      |0.3               |?                 \n",
      "dense_activation  |relu              |?                 \n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 17:04:55.133329: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:55.675413: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:55.754019: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:55.794070: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:55.836215: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:55.953233: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:56.022920: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:04:56.092619: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1/458 [..............................] - ETA: 19:33 - loss: 0.0513 - mae: 0.0513"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 17:04:56.164524: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - ETA: 0s - loss: 0.0497 - mae: 0.0497"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 17:05:06.822141: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:05:07.021896: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:05:07.055281: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:05:07.085126: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:05:07.115646: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "458/458 [==============================] - 15s 26ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 2/100\n",
      "458/458 [==============================] - 12s 25ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 3/100\n",
      "458/458 [==============================] - 11s 23ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 4/100\n",
      "458/458 [==============================] - 11s 24ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 5/100\n",
      "458/458 [==============================] - 10s 23ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 6/100\n",
      "458/458 [==============================] - 11s 23ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 7/100\n",
      "458/458 [==============================] - 11s 25ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 8/100\n",
      "458/458 [==============================] - 11s 24ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 9/100\n",
      "458/458 [==============================] - 11s 23ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 10/100\n",
      "458/458 [==============================] - 11s 24ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 11/100\n",
      "458/458 [==============================] - 11s 24ms/step - loss: 0.0497 - mae: 0.0497 - val_loss: 0.0472 - val_mae: 0.0472\n",
      "Epoch 12/100\n",
      "426/458 [==========================>...] - ETA: 0s - loss: 0.0496 - mae: 0.0496"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 42\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tune_model(train_x, train_y)\n",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 42\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtune_model\u001b[39m(x_train, y_train):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=2'>3</a>\u001b[0m     tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mRandomSearch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=3'>4</a>\u001b[0m         build_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=4'>5</a>\u001b[0m         objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=10'>11</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=11'>12</a>\u001b[0m     tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=12'>13</a>\u001b[0m         x_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=13'>14</a>\u001b[0m         y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=14'>15</a>\u001b[0m         batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=15'>16</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=16'>17</a>\u001b[0m         epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=17'>18</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[callbacks\u001b[39m.\u001b[39;49mTensorBoard(\u001b[39m\"\u001b[39;49m\u001b[39m/tmp/tb_logs\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=19'>20</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=20'>21</a>\u001b[0m     best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_models(num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000037?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_model\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:304\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    303\u001b[0m copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 304\u001b[0m obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    306\u001b[0m \u001b[39m# objective left unspecified,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# and objective value is not a single float.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    309\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj_value, (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m))\n\u001b[1;32m    310\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault_objective\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:234\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    233\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "model = tune_model(train_x, train_y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cleaned_data(hh101, hh101_reversed_mapping, \"hh101\", \"/cleaned_data.png\")\n",
    "# plot_normalised_sensor_activations(\"hh101\", plot_data, hh101_reversed_mapping)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id='hh102'></a>\n",
    "\n",
    "### HH102"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "hh102, hh102_sensor_id_mapping, hh102_reversed_mapping = load_hh102()\n",
    "hh102_drop = [\"LS013\", \"LS006\", \"LS011\", \"M011\", \"MA010\", \"LS012\", \"LS015\", \"LS009\", \"LS023\", \"T101\", \"T102\", \"T103\", \"T104\"]\n",
    "hh102 = transform_data(hh102, hh102_sensor_id_mapping)\n",
    "hh102_removed = remove_sensors(hh102, hh102_drop, hh102_sensor_id_mapping)\n",
    "most_important_features = pca_decomp(hh102_removed)\n",
    "for i, feature in enumerate(most_important_features):\n",
    "    most_important_features[i] = hh102_reversed_mapping[feature]\n",
    "hh102_data, plot_data = transform_series_to_supervised(hh102, HH102_PREDICTION_SENSORS, most_important_features, hh102_reversed_mapping)\n",
    "NUMBER_IN_FEATURES = len(most_important_features)\n",
    "NUMBER_PREDICTIONS = len(HH102_PREDICTION_SENSORS)\n",
    "train_x, train_y, test_x, test_y, anomaly_x, anomaly_y = create_train_test_split(hh102_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Running this cell will create various plots of the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot_cleaned_data(hh102, hh102_reversed_mapping, \"hh102\" , \"/cleaned_data.png\")\n",
    "# plot_normalised_sensor_activations(\"hh102\", plot_data, hh102_reversed_mapping)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Search: Running Trial #1\n",
      "\n",
      "Hyperparameter    |Value             |Best Value So Far \n",
      "input_unit        |450               |?                 \n",
      "n_layers          |1                 |?                 \n",
      "lstm_0_units      |200               |?                 \n",
      "final_lstm_layer  |300               |?                 \n",
      "Dropout_rate      |0                 |?                 \n",
      "dense_activation  |sigmoid           |?                 \n",
      "\n",
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2022-07-25 17:10:15.075333: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:15.495488: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:15.570860: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:15.615374: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:16.028520: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:16.127918: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n",
      "2022-07-25 17:10:16.216950: I tensorflow/core/grappler/optimizers/custom_graph_optimizer_registry.cc:113] Plugin optimizer for device_type GPU is enabled.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "429/459 [===========================>..] - ETA: 0s - loss: 0.0245 - mse: 0.0245"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 49\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=0'>1</a>\u001b[0m model \u001b[39m=\u001b[39m tune_model(train_x, train_y)\n",
      "\u001b[1;32m/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb Cell 49\u001b[0m in \u001b[0;36mtune_model\u001b[0;34m(x_train, y_train)\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtune_model\u001b[39m(x_train, y_train):\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=2'>3</a>\u001b[0m     tuner \u001b[39m=\u001b[39m kt\u001b[39m.\u001b[39mRandomSearch(\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=3'>4</a>\u001b[0m         build_model,\n\u001b[1;32m      <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=4'>5</a>\u001b[0m         objective\u001b[39m=\u001b[39m\u001b[39m'\u001b[39m\u001b[39mmae\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=9'>10</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=10'>11</a>\u001b[0m     )\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=11'>12</a>\u001b[0m     tuner\u001b[39m.\u001b[39;49msearch(\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=12'>13</a>\u001b[0m         x_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=13'>14</a>\u001b[0m         y_train,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=14'>15</a>\u001b[0m         batch_size \u001b[39m=\u001b[39;49m \u001b[39m64\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=15'>16</a>\u001b[0m         validation_split\u001b[39m=\u001b[39;49m\u001b[39m0.2\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=16'>17</a>\u001b[0m         epochs \u001b[39m=\u001b[39;49m \u001b[39m100\u001b[39;49m,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=17'>18</a>\u001b[0m         callbacks\u001b[39m=\u001b[39;49m[callbacks\u001b[39m.\u001b[39;49mTensorBoard(\u001b[39m\"\u001b[39;49m\u001b[39m/tmp/tb_logs\u001b[39;49m\u001b[39m\"\u001b[39;49m)],\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=18'>19</a>\u001b[0m \n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=19'>20</a>\u001b[0m     )\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=20'>21</a>\u001b[0m     best_model \u001b[39m=\u001b[39m tuner\u001b[39m.\u001b[39mget_best_models(num_models\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/christinaspanellis/Desktop/MAC/AAL_ICL/AnomalyDetectionSystem.ipynb#ch0000044?line=21'>22</a>\u001b[0m     \u001b[39mreturn\u001b[39;00m best_model\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/base_tuner.py:179\u001b[0m, in \u001b[0;36mBaseTuner.search\u001b[0;34m(self, *fit_args, **fit_kwargs)\u001b[0m\n\u001b[1;32m    176\u001b[0m     \u001b[39mcontinue\u001b[39;00m\n\u001b[1;32m    178\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mon_trial_begin(trial)\n\u001b[0;32m--> 179\u001b[0m results \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mrun_trial(trial, \u001b[39m*\u001b[39;49mfit_args, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfit_kwargs)\n\u001b[1;32m    180\u001b[0m \u001b[39m# `results` is None indicates user updated oracle in `run_trial()`.\u001b[39;00m\n\u001b[1;32m    181\u001b[0m \u001b[39mif\u001b[39;00m results \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:304\u001b[0m, in \u001b[0;36mTuner.run_trial\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    302\u001b[0m callbacks\u001b[39m.\u001b[39mappend(model_checkpoint)\n\u001b[1;32m    303\u001b[0m copied_kwargs[\u001b[39m\"\u001b[39m\u001b[39mcallbacks\u001b[39m\u001b[39m\"\u001b[39m] \u001b[39m=\u001b[39m callbacks\n\u001b[0;32m--> 304\u001b[0m obj_value \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_build_and_fit_model(trial, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mcopied_kwargs)\n\u001b[1;32m    306\u001b[0m \u001b[39m# objective left unspecified,\u001b[39;00m\n\u001b[1;32m    307\u001b[0m \u001b[39m# and objective value is not a single float.\u001b[39;00m\n\u001b[1;32m    308\u001b[0m \u001b[39mif\u001b[39;00m (\n\u001b[1;32m    309\u001b[0m     \u001b[39mnot\u001b[39;00m \u001b[39misinstance\u001b[39m(obj_value, (\u001b[39mint\u001b[39m, \u001b[39mfloat\u001b[39m))\n\u001b[1;32m    310\u001b[0m     \u001b[39mand\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39moracle\u001b[39m.\u001b[39mobjective\u001b[39m.\u001b[39mname \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefault_objective\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    311\u001b[0m ):\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/tuner.py:234\u001b[0m, in \u001b[0;36mTuner._build_and_fit_model\u001b[0;34m(self, trial, *args, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m hp \u001b[39m=\u001b[39m trial\u001b[39m.\u001b[39mhyperparameters\n\u001b[1;32m    233\u001b[0m model \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_try_build(hp)\n\u001b[0;32m--> 234\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mhypermodel\u001b[39m.\u001b[39;49mfit(hp, model, \u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras_tuner/engine/hypermodel.py:137\u001b[0m, in \u001b[0;36mHyperModel.fit\u001b[0;34m(self, hp, model, *args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mfit\u001b[39m(\u001b[39mself\u001b[39m, hp, model, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs):\n\u001b[1;32m    114\u001b[0m     \u001b[39m\"\"\"Train the model.\u001b[39;00m\n\u001b[1;32m    115\u001b[0m \n\u001b[1;32m    116\u001b[0m \u001b[39m    Args:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[39m        If return a float, it should be the `objective` value.\u001b[39;00m\n\u001b[1;32m    136\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 137\u001b[0m     \u001b[39mreturn\u001b[39;00m model\u001b[39m.\u001b[39;49mfit(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras/utils/traceback_utils.py:64\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     62\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     63\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m---> 64\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     65\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:  \u001b[39m# pylint: disable=broad-except\u001b[39;00m\n\u001b[1;32m     66\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/keras/engine/training.py:1409\u001b[0m, in \u001b[0;36mModel.fit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m   1402\u001b[0m \u001b[39mwith\u001b[39;00m tf\u001b[39m.\u001b[39mprofiler\u001b[39m.\u001b[39mexperimental\u001b[39m.\u001b[39mTrace(\n\u001b[1;32m   1403\u001b[0m     \u001b[39m'\u001b[39m\u001b[39mtrain\u001b[39m\u001b[39m'\u001b[39m,\n\u001b[1;32m   1404\u001b[0m     epoch_num\u001b[39m=\u001b[39mepoch,\n\u001b[1;32m   1405\u001b[0m     step_num\u001b[39m=\u001b[39mstep,\n\u001b[1;32m   1406\u001b[0m     batch_size\u001b[39m=\u001b[39mbatch_size,\n\u001b[1;32m   1407\u001b[0m     _r\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m):\n\u001b[1;32m   1408\u001b[0m   callbacks\u001b[39m.\u001b[39mon_train_batch_begin(step)\n\u001b[0;32m-> 1409\u001b[0m   tmp_logs \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtrain_function(iterator)\n\u001b[1;32m   1410\u001b[0m   \u001b[39mif\u001b[39;00m data_handler\u001b[39m.\u001b[39mshould_sync:\n\u001b[1;32m   1411\u001b[0m     context\u001b[39m.\u001b[39masync_wait()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/util/traceback_utils.py:150\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    148\u001b[0m filtered_tb \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m    149\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 150\u001b[0m   \u001b[39mreturn\u001b[39;00m fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m    151\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mException\u001b[39;00m \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m    152\u001b[0m   filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:915\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    912\u001b[0m compiler \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mxla\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mnonXla\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m    914\u001b[0m \u001b[39mwith\u001b[39;00m OptionalXlaContext(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_jit_compile):\n\u001b[0;32m--> 915\u001b[0m   result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)\n\u001b[1;32m    917\u001b[0m new_tracing_count \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mexperimental_get_tracing_count()\n\u001b[1;32m    918\u001b[0m without_tracing \u001b[39m=\u001b[39m (tracing_count \u001b[39m==\u001b[39m new_tracing_count)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/def_function.py:947\u001b[0m, in \u001b[0;36mFunction._call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    944\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n\u001b[1;32m    945\u001b[0m   \u001b[39m# In this case we have created variables on the first call, so we run the\u001b[39;00m\n\u001b[1;32m    946\u001b[0m   \u001b[39m# defunned version which is guaranteed to never create variables.\u001b[39;00m\n\u001b[0;32m--> 947\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_stateless_fn(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwds)  \u001b[39m# pylint: disable=not-callable\u001b[39;00m\n\u001b[1;32m    948\u001b[0m \u001b[39melif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_stateful_fn \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    949\u001b[0m   \u001b[39m# Release the lock early so that multiple threads can perform the call\u001b[39;00m\n\u001b[1;32m    950\u001b[0m   \u001b[39m# in parallel.\u001b[39;00m\n\u001b[1;32m    951\u001b[0m   \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock\u001b[39m.\u001b[39mrelease()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:2453\u001b[0m, in \u001b[0;36mFunction.__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2450\u001b[0m \u001b[39mwith\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_lock:\n\u001b[1;32m   2451\u001b[0m   (graph_function,\n\u001b[1;32m   2452\u001b[0m    filtered_flat_args) \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_maybe_define_function(args, kwargs)\n\u001b[0;32m-> 2453\u001b[0m \u001b[39mreturn\u001b[39;00m graph_function\u001b[39m.\u001b[39;49m_call_flat(\n\u001b[1;32m   2454\u001b[0m     filtered_flat_args, captured_inputs\u001b[39m=\u001b[39;49mgraph_function\u001b[39m.\u001b[39;49mcaptured_inputs)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:1860\u001b[0m, in \u001b[0;36mConcreteFunction._call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1856\u001b[0m possible_gradient_type \u001b[39m=\u001b[39m gradients_util\u001b[39m.\u001b[39mPossibleTapeGradientTypes(args)\n\u001b[1;32m   1857\u001b[0m \u001b[39mif\u001b[39;00m (possible_gradient_type \u001b[39m==\u001b[39m gradients_util\u001b[39m.\u001b[39mPOSSIBLE_GRADIENT_TYPES_NONE\n\u001b[1;32m   1858\u001b[0m     \u001b[39mand\u001b[39;00m executing_eagerly):\n\u001b[1;32m   1859\u001b[0m   \u001b[39m# No tape is watching; skip to running the function.\u001b[39;00m\n\u001b[0;32m-> 1860\u001b[0m   \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_build_call_outputs(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_inference_function\u001b[39m.\u001b[39;49mcall(\n\u001b[1;32m   1861\u001b[0m       ctx, args, cancellation_manager\u001b[39m=\u001b[39;49mcancellation_manager))\n\u001b[1;32m   1862\u001b[0m forward_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_select_forward_and_backward_functions(\n\u001b[1;32m   1863\u001b[0m     args,\n\u001b[1;32m   1864\u001b[0m     possible_gradient_type,\n\u001b[1;32m   1865\u001b[0m     executing_eagerly)\n\u001b[1;32m   1866\u001b[0m forward_function, args_with_tangents \u001b[39m=\u001b[39m forward_backward\u001b[39m.\u001b[39mforward()\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/function.py:497\u001b[0m, in \u001b[0;36m_EagerDefinedFunction.call\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    495\u001b[0m \u001b[39mwith\u001b[39;00m _InterpolateFunctionError(\u001b[39mself\u001b[39m):\n\u001b[1;32m    496\u001b[0m   \u001b[39mif\u001b[39;00m cancellation_manager \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m--> 497\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39;49mexecute(\n\u001b[1;32m    498\u001b[0m         \u001b[39mstr\u001b[39;49m(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msignature\u001b[39m.\u001b[39;49mname),\n\u001b[1;32m    499\u001b[0m         num_outputs\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_num_outputs,\n\u001b[1;32m    500\u001b[0m         inputs\u001b[39m=\u001b[39;49margs,\n\u001b[1;32m    501\u001b[0m         attrs\u001b[39m=\u001b[39;49mattrs,\n\u001b[1;32m    502\u001b[0m         ctx\u001b[39m=\u001b[39;49mctx)\n\u001b[1;32m    503\u001b[0m   \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    504\u001b[0m     outputs \u001b[39m=\u001b[39m execute\u001b[39m.\u001b[39mexecute_with_cancellation(\n\u001b[1;32m    505\u001b[0m         \u001b[39mstr\u001b[39m(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39msignature\u001b[39m.\u001b[39mname),\n\u001b[1;32m    506\u001b[0m         num_outputs\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_outputs,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    509\u001b[0m         ctx\u001b[39m=\u001b[39mctx,\n\u001b[1;32m    510\u001b[0m         cancellation_manager\u001b[39m=\u001b[39mcancellation_manager)\n",
      "File \u001b[0;32m~/miniforge3/envs/mscproj/lib/python3.9/site-packages/tensorflow/python/eager/execute.py:54\u001b[0m, in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     52\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m     53\u001b[0m   ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 54\u001b[0m   tensors \u001b[39m=\u001b[39m pywrap_tfe\u001b[39m.\u001b[39;49mTFE_Py_Execute(ctx\u001b[39m.\u001b[39;49m_handle, device_name, op_name,\n\u001b[1;32m     55\u001b[0m                                       inputs, attrs, num_outputs)\n\u001b[1;32m     56\u001b[0m \u001b[39mexcept\u001b[39;00m core\u001b[39m.\u001b[39m_NotOkStatusException \u001b[39mas\u001b[39;00m e:\n\u001b[1;32m     57\u001b[0m   \u001b[39mif\u001b[39;00m name \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model = tune_model(train_x, train_y)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('mscproj')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "d17618d7e163c2a95ac78e25d7966a2827f51b90d43fb3fa6b15fe17847d1ec4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
